#!/usr/bin/env node
/**
 * AgentDB MCP Server
 * Production-ready MCP server for Claude Desktop integration
 * Exposes AgentDB frontier memory features + core vector DB operations via MCP protocol
 */
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { CallToolRequestSchema, ListToolsRequestSchema, } from '@modelcontextprotocol/sdk/types.js';
import { createDatabase } from '../db-fallback.js';
import { CausalMemoryGraph } from '../controllers/CausalMemoryGraph.js';
import { CausalRecall } from '../controllers/CausalRecall.js';
import { ReflexionMemory } from '../controllers/ReflexionMemory.js';
import { SkillLibrary } from '../controllers/SkillLibrary.js';
import { NightlyLearner } from '../controllers/NightlyLearner.js';
import { LearningSystem } from '../controllers/LearningSystem.js';
import { EmbeddingService } from '../controllers/EmbeddingService.js';
import { BatchOperations } from '../optimizations/BatchOperations.js';
import { ReasoningBank } from '../controllers/ReasoningBank.js';
import { validateId, validateTimestamp, validateSessionId, ValidationError, handleSecurityError, } from '../security/input-validation.js';
import * as path from 'path';
import * as fs from 'fs';
import { fileURLToPath } from 'url';
import { dirname } from 'path';
// ES module equivalent of __dirname
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
// ============================================================================
// Helper Functions for Core Vector DB Operations
// ============================================================================
/**
 * Initialize database schema
 */
function initializeSchema(database) {
    const db = database;
    // Episodes table (vector store)
    db.exec(`
    CREATE TABLE IF NOT EXISTS episodes (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      ts INTEGER DEFAULT (strftime('%s', 'now')),
      session_id TEXT NOT NULL,
      task TEXT NOT NULL,
      input TEXT,
      output TEXT,
      critique TEXT,
      reward REAL NOT NULL,
      success INTEGER NOT NULL,
      latency_ms INTEGER,
      tokens_used INTEGER,
      tags TEXT,
      metadata TEXT
    );

    CREATE INDEX IF NOT EXISTS idx_episodes_session ON episodes(session_id);
    CREATE INDEX IF NOT EXISTS idx_episodes_task ON episodes(task);
    CREATE INDEX IF NOT EXISTS idx_episodes_reward ON episodes(reward);
    CREATE INDEX IF NOT EXISTS idx_episodes_success ON episodes(success);
  `);
    // Episode embeddings (vector storage)
    db.exec(`
    CREATE TABLE IF NOT EXISTS episode_embeddings (
      episode_id INTEGER PRIMARY KEY,
      embedding BLOB NOT NULL,
      FOREIGN KEY (episode_id) REFERENCES episodes(id) ON DELETE CASCADE
    );
  `);
    // Skills table
    db.exec(`
    CREATE TABLE IF NOT EXISTS skills (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      ts INTEGER DEFAULT (strftime('%s', 'now')),
      name TEXT UNIQUE NOT NULL,
      description TEXT NOT NULL,
      signature TEXT,
      code TEXT,
      success_rate REAL DEFAULT 0.0,
      uses INTEGER DEFAULT 0,
      avg_reward REAL DEFAULT 0.0,
      avg_latency_ms REAL DEFAULT 0.0,
      tags TEXT,
      metadata TEXT
    );

    CREATE INDEX IF NOT EXISTS idx_skills_success_rate ON skills(success_rate);
  `);
    // Skill embeddings
    db.exec(`
    CREATE TABLE IF NOT EXISTS skill_embeddings (
      skill_id INTEGER PRIMARY KEY,
      embedding BLOB NOT NULL,
      FOREIGN KEY (skill_id) REFERENCES skills(id) ON DELETE CASCADE
    );
  `);
    // Causal edges table
    db.exec(`
    CREATE TABLE IF NOT EXISTS causal_edges (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      ts INTEGER DEFAULT (strftime('%s', 'now')),
      from_memory_id INTEGER NOT NULL,
      from_memory_type TEXT NOT NULL,
      to_memory_id INTEGER NOT NULL,
      to_memory_type TEXT NOT NULL,
      similarity REAL DEFAULT 0.0,
      uplift REAL NOT NULL,
      confidence REAL DEFAULT 0.95,
      sample_size INTEGER DEFAULT 0,
      evidence_ids TEXT,
      experiment_ids TEXT,
      confounder_score REAL DEFAULT 0.0,
      mechanism TEXT,
      metadata TEXT
    );

    CREATE INDEX IF NOT EXISTS idx_causal_from ON causal_edges(from_memory_id, from_memory_type);
    CREATE INDEX IF NOT EXISTS idx_causal_to ON causal_edges(to_memory_id, to_memory_type);
    CREATE INDEX IF NOT EXISTS idx_causal_uplift ON causal_edges(uplift);
  `);
    // Causal experiments
    db.exec(`
    CREATE TABLE IF NOT EXISTS causal_experiments (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      ts INTEGER DEFAULT (strftime('%s', 'now')),
      intervention_id INTEGER NOT NULL,
      control_outcome REAL NOT NULL,
      treatment_outcome REAL NOT NULL,
      uplift REAL NOT NULL,
      sample_size INTEGER DEFAULT 1,
      metadata TEXT
    );
  `);
    // Causal observations
    db.exec(`
    CREATE TABLE IF NOT EXISTS causal_observations (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      ts INTEGER DEFAULT (strftime('%s', 'now')),
      action TEXT NOT NULL,
      outcome TEXT NOT NULL,
      reward REAL NOT NULL,
      session_id TEXT,
      metadata TEXT
    );
  `);
    // Provenance certificates
    db.exec(`
    CREATE TABLE IF NOT EXISTS provenance_certificates (
      id TEXT PRIMARY KEY,
      ts INTEGER DEFAULT (strftime('%s', 'now')),
      query_id TEXT NOT NULL,
      agent_id TEXT NOT NULL,
      query_text TEXT NOT NULL,
      retrieval_method TEXT NOT NULL,
      source_ids TEXT NOT NULL,
      certificate_hash TEXT NOT NULL,
      metadata TEXT
    );
  `);
}
/**
 * Serialize embedding to BLOB
 */
function serializeEmbedding(embedding) {
    return Buffer.from(embedding.buffer);
}
/**
 * Deserialize embedding from BLOB
 */
function deserializeEmbedding(blob) {
    return new Float32Array(blob.buffer, blob.byteOffset, blob.byteLength / 4);
}
/**
 * Calculate cosine similarity between two vectors
 */
function cosineSimilarity(a, b) {
    if (a.length !== b.length) {
        throw new Error('Vectors must have same length');
    }
    let dotProduct = 0;
    let normA = 0;
    let normB = 0;
    for (let i = 0; i < a.length; i++) {
        dotProduct += a[i] * b[i];
        normA += a[i] * a[i];
        normB += b[i] * b[i];
    }
    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
// ============================================================================
// Initialize Database and Controllers
// ============================================================================
const dbPath = process.env.AGENTDB_PATH || './agentdb.db';
const db = await createDatabase(dbPath);
// Configure for performance
db.pragma('journal_mode = WAL');
db.pragma('synchronous = NORMAL');
db.pragma('cache_size = -64000');
// Initialize schema automatically on server start using SQL files
const schemaPath = path.join(__dirname, '../schemas/schema.sql');
const frontierSchemaPath = path.join(__dirname, '../schemas/frontier-schema.sql');
try {
    if (fs.existsSync(schemaPath)) {
        const schemaSQL = fs.readFileSync(schemaPath, 'utf-8');
        db.exec(schemaSQL);
        console.error('âœ… Main schema loaded');
    }
    if (fs.existsSync(frontierSchemaPath)) {
        const frontierSQL = fs.readFileSync(frontierSchemaPath, 'utf-8');
        db.exec(frontierSQL);
        console.error('âœ… Frontier schema loaded');
    }
    console.error('âœ… Database schema initialized');
}
catch (error) {
    console.error('âš ï¸  Schema initialization failed, using fallback:', error.message);
    // Fallback to initializeSchema function if SQL files not found
    initializeSchema(db);
}
// Initialize embedding service
const embeddingService = new EmbeddingService({
    model: 'Xenova/all-MiniLM-L6-v2',
    dimension: 384,
    provider: 'transformers'
});
await embeddingService.initialize();
// Initialize all controllers
const causalGraph = new CausalMemoryGraph(db);
const reflexion = new ReflexionMemory(db, embeddingService);
const skills = new SkillLibrary(db, embeddingService);
const causalRecall = new CausalRecall(db, embeddingService);
const learner = new NightlyLearner(db, embeddingService);
const learningSystem = new LearningSystem(db, embeddingService);
const batchOps = new BatchOperations(db, embeddingService);
const reasoningBank = new ReasoningBank(db, embeddingService);
// ============================================================================
// MCP Server Setup
// ============================================================================
const server = new Server({
    name: 'agentdb',
    version: '1.3.0',
}, {
    capabilities: {
        tools: {},
    },
});
// ============================================================================
// Tool Definitions
// ============================================================================
const tools = [
    // ==========================================================================
    // CORE VECTOR DB OPERATIONS (NEW)
    // ==========================================================================
    {
        name: 'agentdb_init',
        description: 'Initialize AgentDB database with schema and optimizations. Creates all required tables for vector storage, causal memory, skills, and provenance tracking.',
        inputSchema: {
            type: 'object',
            properties: {
                db_path: { type: 'string', description: 'Database file path (optional, defaults to ./agentdb.db)', default: './agentdb.db' },
                reset: { type: 'boolean', description: 'Reset database (delete existing)', default: false },
            },
        },
    },
    {
        name: 'agentdb_insert',
        description: 'Insert a single vector with metadata into AgentDB. Automatically generates embeddings for the provided text.',
        inputSchema: {
            type: 'object',
            properties: {
                text: { type: 'string', description: 'Text content to embed and store' },
                metadata: { type: 'object', description: 'Additional metadata (JSON object)' },
                session_id: { type: 'string', description: 'Session identifier', default: 'default' },
                tags: { type: 'array', items: { type: 'string' }, description: 'Tags for categorization' },
            },
            required: ['text'],
        },
    },
    {
        name: 'agentdb_insert_batch',
        description: 'Batch insert multiple vectors efficiently using transactions and parallel embedding generation. Optimized for large datasets.',
        inputSchema: {
            type: 'object',
            properties: {
                items: {
                    type: 'array',
                    items: {
                        type: 'object',
                        properties: {
                            text: { type: 'string', description: 'Text content to embed' },
                            metadata: { type: 'object', description: 'Metadata (JSON)' },
                            session_id: { type: 'string', description: 'Session ID' },
                            tags: { type: 'array', items: { type: 'string' } },
                        },
                        required: ['text'],
                    },
                    description: 'Array of items to insert',
                },
                batch_size: { type: 'number', description: 'Batch size for processing', default: 100 },
            },
            required: ['items'],
        },
    },
    {
        name: 'agentdb_search',
        description: 'Semantic k-NN vector search using cosine similarity. Returns the most relevant results ranked by similarity score.',
        inputSchema: {
            type: 'object',
            properties: {
                query: { type: 'string', description: 'Search query text' },
                k: { type: 'number', description: 'Number of results to return', default: 10 },
                min_similarity: { type: 'number', description: 'Minimum similarity threshold (0-1)', default: 0.0 },
                filters: {
                    type: 'object',
                    properties: {
                        session_id: { type: 'string', description: 'Filter by session ID' },
                        tags: { type: 'array', items: { type: 'string' }, description: 'Filter by tags' },
                        min_reward: { type: 'number', description: 'Minimum reward threshold' },
                    },
                    description: 'Optional filters',
                },
            },
            required: ['query'],
        },
    },
    {
        name: 'agentdb_delete',
        description: 'Delete vector(s) from AgentDB by ID or filters. Supports single ID deletion or bulk deletion with conditions.',
        inputSchema: {
            type: 'object',
            properties: {
                id: { type: 'number', description: 'Specific vector ID to delete' },
                filters: {
                    type: 'object',
                    properties: {
                        session_id: { type: 'string', description: 'Delete all vectors with this session ID' },
                        before_timestamp: { type: 'number', description: 'Delete vectors before this Unix timestamp' },
                    },
                    description: 'Bulk deletion filters (used if id not provided)',
                },
            },
        },
    },
    // ==========================================================================
    // FRONTIER MEMORY FEATURES (EXISTING)
    // ==========================================================================
    {
        name: 'reflexion_store',
        description: 'Store an episode with self-critique for reflexion-based learning',
        inputSchema: {
            type: 'object',
            properties: {
                session_id: { type: 'string', description: 'Session identifier' },
                task: { type: 'string', description: 'Task description' },
                reward: { type: 'number', description: 'Task reward (0-1)' },
                success: { type: 'boolean', description: 'Whether task succeeded' },
                critique: { type: 'string', description: 'Self-critique reflection' },
                input: { type: 'string', description: 'Task input' },
                output: { type: 'string', description: 'Task output' },
                latency_ms: { type: 'number', description: 'Execution latency' },
                tokens: { type: 'number', description: 'Tokens used' },
            },
            required: ['session_id', 'task', 'reward', 'success'],
        },
    },
    {
        name: 'reflexion_retrieve',
        description: 'Retrieve relevant past episodes for learning from experience',
        inputSchema: {
            type: 'object',
            properties: {
                task: { type: 'string', description: 'Task to find similar episodes for' },
                k: { type: 'number', description: 'Number of episodes to retrieve', default: 5 },
                only_failures: { type: 'boolean', description: 'Only retrieve failures' },
                only_successes: { type: 'boolean', description: 'Only retrieve successes' },
                min_reward: { type: 'number', description: 'Minimum reward threshold' },
            },
            required: ['task'],
        },
    },
    {
        name: 'skill_create',
        description: 'Create a reusable skill in the skill library',
        inputSchema: {
            type: 'object',
            properties: {
                name: { type: 'string', description: 'Skill name' },
                description: { type: 'string', description: 'What the skill does' },
                code: { type: 'string', description: 'Skill implementation code' },
                success_rate: { type: 'number', description: 'Initial success rate' },
            },
            required: ['name', 'description'],
        },
    },
    {
        name: 'skill_search',
        description: 'Search for applicable skills by semantic similarity',
        inputSchema: {
            type: 'object',
            properties: {
                task: { type: 'string', description: 'Task to find skills for' },
                k: { type: 'number', description: 'Number of skills to return', default: 10 },
                min_success_rate: { type: 'number', description: 'Minimum success rate filter' },
            },
            required: ['task'],
        },
    },
    {
        name: 'causal_add_edge',
        description: 'Add a causal relationship between actions and outcomes',
        inputSchema: {
            type: 'object',
            properties: {
                cause: { type: 'string', description: 'Causal action/intervention' },
                effect: { type: 'string', description: 'Observed effect/outcome' },
                uplift: { type: 'number', description: 'Causal uplift magnitude' },
                confidence: { type: 'number', description: 'Confidence in causal claim (0-1)', default: 0.95 },
                sample_size: { type: 'number', description: 'Number of observations', default: 0 },
            },
            required: ['cause', 'effect', 'uplift'],
        },
    },
    {
        name: 'causal_query',
        description: 'Query causal effects to understand what actions cause what outcomes',
        inputSchema: {
            type: 'object',
            properties: {
                cause: { type: 'string', description: 'Filter by cause (optional)' },
                effect: { type: 'string', description: 'Filter by effect (optional)' },
                min_confidence: { type: 'number', description: 'Minimum confidence', default: 0.5 },
                min_uplift: { type: 'number', description: 'Minimum uplift', default: 0.0 },
                limit: { type: 'number', description: 'Maximum results', default: 10 },
            },
        },
    },
    {
        name: 'recall_with_certificate',
        description: 'Retrieve memories with causal utility scoring and provenance certificate',
        inputSchema: {
            type: 'object',
            properties: {
                query: { type: 'string', description: 'Query for memory retrieval' },
                k: { type: 'number', description: 'Number of results', default: 12 },
                alpha: { type: 'number', description: 'Similarity weight', default: 0.7 },
                beta: { type: 'number', description: 'Causal uplift weight', default: 0.2 },
                gamma: { type: 'number', description: 'Recency weight', default: 0.1 },
            },
            required: ['query'],
        },
    },
    {
        name: 'learner_discover',
        description: 'Automatically discover causal patterns from episode history',
        inputSchema: {
            type: 'object',
            properties: {
                min_attempts: { type: 'number', description: 'Minimum attempts required', default: 3 },
                min_success_rate: { type: 'number', description: 'Minimum success rate', default: 0.6 },
                min_confidence: { type: 'number', description: 'Minimum statistical confidence', default: 0.7 },
                dry_run: { type: 'boolean', description: 'Preview without storing', default: false },
            },
        },
    },
    {
        name: 'db_stats',
        description: 'Get database statistics showing record counts',
        inputSchema: {
            type: 'object',
            properties: {},
        },
    },
    // ==========================================================================
    // LEARNING SYSTEM TOOLS (v1.3.0 - Tools 1-5)
    // ==========================================================================
    {
        name: 'learning_start_session',
        description: 'Start a new reinforcement learning session with specified algorithm and configuration. Supports 9 RL algorithms: q-learning, sarsa, dqn, policy-gradient, actor-critic, ppo, decision-transformer, mcts, model-based.',
        inputSchema: {
            type: 'object',
            properties: {
                user_id: { type: 'string', description: 'User identifier for the learning session' },
                session_type: {
                    type: 'string',
                    description: 'RL algorithm type',
                    enum: ['q-learning', 'sarsa', 'dqn', 'policy-gradient', 'actor-critic', 'ppo', 'decision-transformer', 'mcts', 'model-based'],
                },
                config: {
                    type: 'object',
                    description: 'Learning configuration parameters',
                    properties: {
                        learning_rate: { type: 'number', description: 'Learning rate (0-1)', default: 0.01 },
                        discount_factor: { type: 'number', description: 'Discount factor gamma (0-1)', default: 0.99 },
                        exploration_rate: { type: 'number', description: 'Epsilon for epsilon-greedy exploration (0-1)', default: 0.1 },
                        batch_size: { type: 'number', description: 'Batch size for training', default: 32 },
                        target_update_frequency: { type: 'number', description: 'Update frequency for target network', default: 100 },
                    },
                    required: ['learning_rate', 'discount_factor'],
                },
            },
            required: ['user_id', 'session_type', 'config'],
        },
    },
    {
        name: 'learning_end_session',
        description: 'End an active learning session and save the final trained policy to the database.',
        inputSchema: {
            type: 'object',
            properties: {
                session_id: { type: 'string', description: 'Session ID to end' },
            },
            required: ['session_id'],
        },
    },
    {
        name: 'learning_predict',
        description: 'Get AI-recommended action for a given state with confidence scores and alternative actions.',
        inputSchema: {
            type: 'object',
            properties: {
                session_id: { type: 'string', description: 'Learning session ID' },
                state: { type: 'string', description: 'Current state description' },
            },
            required: ['session_id', 'state'],
        },
    },
    {
        name: 'learning_feedback',
        description: 'Submit feedback on action quality to train the RL policy. Feedback includes reward signal and outcome state.',
        inputSchema: {
            type: 'object',
            properties: {
                session_id: { type: 'string', description: 'Learning session ID' },
                state: { type: 'string', description: 'State where action was taken' },
                action: { type: 'string', description: 'Action that was executed' },
                reward: { type: 'number', description: 'Reward received (higher is better)' },
                next_state: { type: 'string', description: 'Resulting state after action (optional)' },
                success: { type: 'boolean', description: 'Whether the action was successful' },
            },
            required: ['session_id', 'state', 'action', 'reward', 'success'],
        },
    },
    {
        name: 'learning_train',
        description: 'Train the RL policy using batch learning with collected experiences. Returns training metrics including loss, average reward, and convergence rate.',
        inputSchema: {
            type: 'object',
            properties: {
                session_id: { type: 'string', description: 'Learning session ID to train' },
                epochs: { type: 'number', description: 'Number of training epochs', default: 50 },
                batch_size: { type: 'number', description: 'Batch size for training', default: 32 },
                learning_rate: { type: 'number', description: 'Learning rate for this training run', default: 0.01 },
            },
            required: ['session_id'],
        },
    },
    // ==========================================================================
    // LEARNING SYSTEM TOOLS (v1.4.0 - Tools 6-10)
    // ==========================================================================
    {
        name: 'learning_metrics',
        description: 'Get learning performance metrics including success rates, rewards, and policy improvement',
        inputSchema: {
            type: 'object',
            properties: {
                session_id: { type: 'string', description: 'Optional session ID to filter metrics' },
                time_window_days: { type: 'number', description: 'Time window in days for metrics (default: 7)', default: 7 },
                include_trends: { type: 'boolean', description: 'Include trend analysis over time', default: true },
                group_by: { type: 'string', description: 'Group metrics by task/session/skill', enum: ['task', 'session', 'skill'], default: 'task' },
            },
        },
    },
    {
        name: 'learning_transfer',
        description: 'Transfer learning between sessions or tasks, enabling knowledge reuse across different contexts',
        inputSchema: {
            type: 'object',
            properties: {
                source_session: { type: 'string', description: 'Source session ID to transfer from' },
                target_session: { type: 'string', description: 'Target session ID to transfer to' },
                source_task: { type: 'string', description: 'Source task pattern to transfer from' },
                target_task: { type: 'string', description: 'Target task pattern to transfer to' },
                min_similarity: { type: 'number', description: 'Minimum similarity threshold (0-1)', default: 0.7, minimum: 0, maximum: 1 },
                transfer_type: { type: 'string', description: 'Type of transfer', enum: ['episodes', 'skills', 'causal_edges', 'all'], default: 'all' },
                max_transfers: { type: 'number', description: 'Maximum number of items to transfer', default: 10 },
            },
        },
    },
    {
        name: 'learning_explain',
        description: 'Explain action recommendations with confidence scores and supporting evidence from past experiences',
        inputSchema: {
            type: 'object',
            properties: {
                query: { type: 'string', description: 'Query or task description to get recommendations for' },
                k: { type: 'number', description: 'Number of recommendations to return', default: 5 },
                explain_depth: { type: 'string', description: 'Explanation detail level', enum: ['summary', 'detailed', 'full'], default: 'detailed' },
                include_confidence: { type: 'boolean', description: 'Include confidence scores', default: true },
                include_evidence: { type: 'boolean', description: 'Include supporting evidence from past episodes', default: true },
                include_causal: { type: 'boolean', description: 'Include causal reasoning chains', default: true },
            },
            required: ['query'],
        },
    },
    {
        name: 'experience_record',
        description: 'Record tool execution as experience for reinforcement learning and experience replay',
        inputSchema: {
            type: 'object',
            properties: {
                session_id: { type: 'string', description: 'Session identifier' },
                tool_name: { type: 'string', description: 'Name of the tool executed' },
                action: { type: 'string', description: 'Action taken or tool parameters' },
                state_before: { type: 'object', description: 'System state before action (JSON)' },
                state_after: { type: 'object', description: 'System state after action (JSON)' },
                outcome: { type: 'string', description: 'Outcome description' },
                reward: { type: 'number', description: 'Reward signal (0-1)', minimum: 0, maximum: 1 },
                success: { type: 'boolean', description: 'Whether the action succeeded' },
                latency_ms: { type: 'number', description: 'Execution latency in milliseconds' },
                metadata: { type: 'object', description: 'Additional metadata (JSON)' },
            },
            required: ['session_id', 'tool_name', 'action', 'outcome', 'reward', 'success'],
        },
    },
    {
        name: 'reward_signal',
        description: 'Calculate reward signal for outcomes based on success, efficiency, and causal impact',
        inputSchema: {
            type: 'object',
            properties: {
                episode_id: { type: 'number', description: 'Episode ID to calculate reward for' },
                success: { type: 'boolean', description: 'Whether the outcome was successful' },
                target_achieved: { type: 'boolean', description: 'Whether the target was achieved', default: true },
                efficiency_score: { type: 'number', description: 'Efficiency score (0-1)', default: 0.5, minimum: 0, maximum: 1 },
                quality_score: { type: 'number', description: 'Quality score (0-1)', default: 0.5, minimum: 0, maximum: 1 },
                time_taken_ms: { type: 'number', description: 'Time taken in milliseconds' },
                expected_time_ms: { type: 'number', description: 'Expected time in milliseconds' },
                include_causal: { type: 'boolean', description: 'Include causal impact in reward', default: true },
                reward_function: { type: 'string', description: 'Reward function to use', enum: ['standard', 'sparse', 'dense', 'shaped'], default: 'standard' },
            },
            required: ['success'],
        },
    },
    // ==========================================================================
    // CORE AGENTDB TOOLS (6-10) - v1.3.0
    // ==========================================================================
    {
        name: 'agentdb_stats',
        description: 'Get comprehensive database statistics including table counts, storage usage, and performance metrics',
        inputSchema: {
            type: 'object',
            properties: {
                detailed: { type: 'boolean', description: 'Include detailed statistics', default: false },
            },
        },
    },
    {
        name: 'agentdb_pattern_store',
        description: 'Store reasoning pattern with embedding, taskType, approach, and successRate',
        inputSchema: {
            type: 'object',
            properties: {
                taskType: { type: 'string', description: 'Type of task (e.g., "code_review", "data_analysis")' },
                approach: { type: 'string', description: 'Description of the reasoning approach' },
                successRate: { type: 'number', description: 'Success rate (0-1)', default: 0.0 },
                tags: { type: 'array', items: { type: 'string' }, description: 'Optional tags' },
                metadata: { type: 'object', description: 'Additional metadata' },
            },
            required: ['taskType', 'approach', 'successRate'],
        },
    },
    {
        name: 'agentdb_pattern_search',
        description: 'Search patterns with taskEmbedding, k, threshold, and filters',
        inputSchema: {
            type: 'object',
            properties: {
                task: { type: 'string', description: 'Task description to search for' },
                k: { type: 'number', description: 'Number of results to return', default: 10 },
                threshold: { type: 'number', description: 'Minimum similarity threshold (0-1)', default: 0.0 },
                filters: {
                    type: 'object',
                    properties: {
                        taskType: { type: 'string', description: 'Filter by task type' },
                        minSuccessRate: { type: 'number', description: 'Minimum success rate' },
                        tags: { type: 'array', items: { type: 'string' }, description: 'Filter by tags' },
                    },
                    description: 'Optional filters',
                },
            },
            required: ['task'],
        },
    },
    {
        name: 'agentdb_pattern_stats',
        description: 'Get pattern statistics including total patterns, success rates, and top task types',
        inputSchema: {
            type: 'object',
            properties: {},
        },
    },
    {
        name: 'agentdb_clear_cache',
        description: 'Clear query cache to refresh statistics and search results',
        inputSchema: {
            type: 'object',
            properties: {
                cache_type: {
                    type: 'string',
                    description: 'Type of cache to clear (all, patterns, stats)',
                    enum: ['all', 'patterns', 'stats'],
                    default: 'all'
                },
            },
        },
    },
];
// ============================================================================
// Tool Handlers
// ============================================================================
server.setRequestHandler(ListToolsRequestSchema, async () => {
    return { tools };
});
server.setRequestHandler(CallToolRequestSchema, async (request) => {
    const { name, arguments: args } = request.params;
    try {
        switch (name) {
            // ======================================================================
            // CORE VECTOR DB OPERATIONS
            // ======================================================================
            case 'agentdb_init': {
                const targetDbPath = args?.db_path || dbPath;
                if (args?.reset && fs.existsSync(targetDbPath)) {
                    fs.unlinkSync(targetDbPath);
                }
                // Initialize schema
                initializeSchema(db);
                const stats = db.prepare('SELECT COUNT(*) as count FROM sqlite_master WHERE type="table"').get();
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… AgentDB initialized successfully!\n` +
                                `ðŸ“ Database: ${targetDbPath}\n` +
                                `ðŸ“Š Tables created: ${stats.count}\n` +
                                `âš™ï¸  Optimizations: WAL mode, cache_size=64MB\n` +
                                `ðŸ§  Embedding service: ${embeddingService.constructor.name} ready`,
                        },
                    ],
                };
            }
            case 'agentdb_insert': {
                const text = args?.text;
                const sessionId = args?.session_id || 'default';
                const tags = args?.tags || [];
                const metadata = args?.metadata || {};
                const episodeId = await reflexion.storeEpisode({
                    sessionId,
                    task: text,
                    reward: 1.0,
                    success: true,
                    input: text,
                    output: '',
                    critique: '',
                    latencyMs: 0,
                    tokensUsed: 0,
                    tags,
                    metadata,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Vector inserted successfully!\n` +
                                `ðŸ†” ID: ${episodeId}\n` +
                                `ðŸ“ Text: ${text.substring(0, 100)}${text.length > 100 ? '...' : ''}\n` +
                                `ðŸ·ï¸  Tags: ${tags.join(', ') || 'none'}\n` +
                                `ðŸ§  Embedding: ${embeddingService.constructor.name}`,
                        },
                    ],
                };
            }
            case 'agentdb_insert_batch': {
                const items = args?.items || [];
                const batchSize = args?.batch_size || 100;
                const episodes = items.map((item) => ({
                    sessionId: item.session_id || 'default',
                    task: item.text,
                    reward: 1.0,
                    success: true,
                    input: item.text,
                    output: '',
                    critique: '',
                    latencyMs: 0,
                    tokensUsed: 0,
                    tags: item.tags || [],
                    metadata: item.metadata || {},
                }));
                const batchOpsConfig = new BatchOperations(db, embeddingService, {
                    batchSize,
                    parallelism: 4,
                });
                const inserted = await batchOpsConfig.insertEpisodes(episodes);
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Batch insert completed!\n` +
                                `ðŸ“Š Inserted: ${inserted} vectors\n` +
                                `âš¡ Batch size: ${batchSize}\n` +
                                `ðŸ§  Embeddings generated in parallel\n` +
                                `ðŸ’¾ Transaction committed`,
                        },
                    ],
                };
            }
            case 'agentdb_search': {
                const queryText = args?.query;
                const k = args?.k || 10;
                const minSimilarity = args?.min_similarity || 0.0;
                const filters = args?.filters;
                const query = {
                    task: queryText,
                    k,
                };
                if (filters) {
                    if (filters.min_reward !== undefined) {
                        query.minReward = filters.min_reward;
                    }
                    // Session ID filter would require custom query
                }
                const results = await reflexion.retrieveRelevant(query);
                // Filter by minimum similarity if specified
                let filteredResults = results;
                if (minSimilarity > 0) {
                    filteredResults = results.filter(r => (r.similarity || 0) >= minSimilarity);
                }
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ” Search completed!\n` +
                                `ðŸ“Š Found: ${filteredResults.length} results\n` +
                                `ðŸŽ¯ Query: ${queryText}\n\n` +
                                `Top Results:\n` +
                                filteredResults.slice(0, 5).map((r, i) => `${i + 1}. [ID: ${r.id}] Similarity: ${(r.similarity || 0).toFixed(3)}\n` +
                                    `   Task: ${r.task.substring(0, 80)}${r.task.length > 80 ? '...' : ''}\n` +
                                    `   Reward: ${r.reward.toFixed(2)}`).join('\n\n') +
                                (filteredResults.length > 5 ? `\n\n... and ${filteredResults.length - 5} more results` : ''),
                        },
                    ],
                };
            }
            case 'agentdb_delete': {
                let deleted = 0;
                const id = args?.id;
                const filters = args?.filters;
                try {
                    if (id !== undefined) {
                        // Validate ID
                        const validatedId = validateId(id, 'id');
                        // Delete single vector using parameterized query
                        const stmt = db.prepare('DELETE FROM episodes WHERE id = ?');
                        const result = stmt.run(validatedId);
                        deleted = result.changes;
                    }
                    else if (filters) {
                        // Bulk delete with validated filters
                        if (filters.session_id) {
                            // Validate session_id
                            const validatedSessionId = validateSessionId(filters.session_id);
                            // Use parameterized query
                            const stmt = db.prepare('DELETE FROM episodes WHERE session_id = ?');
                            const result = stmt.run(validatedSessionId);
                            deleted = result.changes;
                        }
                        else if (filters.before_timestamp) {
                            // Validate timestamp
                            const validatedTimestamp = validateTimestamp(filters.before_timestamp, 'before_timestamp');
                            // Use parameterized query
                            const stmt = db.prepare('DELETE FROM episodes WHERE ts < ?');
                            const result = stmt.run(validatedTimestamp);
                            deleted = result.changes;
                        }
                        else {
                            throw new ValidationError('Invalid or missing filter criteria', 'INVALID_FILTER');
                        }
                    }
                    else {
                        throw new ValidationError('Either id or filters must be provided', 'MISSING_PARAMETER');
                    }
                    return {
                        content: [
                            {
                                type: 'text',
                                text: `âœ… Delete operation completed!\n` +
                                    `ðŸ“Š Deleted: ${deleted} vector(s)\n` +
                                    `ðŸ—‘ï¸  ${id !== undefined ? `ID: ${id}` : 'Bulk deletion with filters'}`,
                            },
                        ],
                    };
                }
                catch (error) {
                    const safeMessage = handleSecurityError(error);
                    return {
                        content: [
                            {
                                type: 'text',
                                text: `âŒ Delete operation failed: ${safeMessage}`,
                            },
                        ],
                        isError: true,
                    };
                }
            }
            // ======================================================================
            // FRONTIER MEMORY FEATURES (EXISTING)
            // ======================================================================
            case 'reflexion_store': {
                const episodeId = await reflexion.storeEpisode({
                    sessionId: args?.session_id,
                    task: args?.task,
                    reward: args?.reward,
                    success: args?.success,
                    critique: args?.critique || '',
                    input: args?.input || '',
                    output: args?.output || '',
                    latencyMs: args?.latency_ms || 0,
                    tokensUsed: args?.tokens || 0,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Stored episode #${episodeId}\nTask: ${args?.task}\nReward: ${args?.reward}\nSuccess: ${args?.success}`,
                        },
                    ],
                };
            }
            case 'reflexion_retrieve': {
                const episodes = await reflexion.retrieveRelevant({
                    task: args?.task,
                    k: args?.k || 5,
                    onlyFailures: args?.only_failures,
                    onlySuccesses: args?.only_successes,
                    minReward: args?.min_reward,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ” Retrieved ${episodes.length} episodes:\n\n` +
                                episodes.map((ep, i) => `${i + 1}. Episode ${ep.id}\n   Task: ${ep.task}\n   Reward: ${ep.reward.toFixed(2)}\n   Similarity: ${ep.similarity?.toFixed(3) || 'N/A'}`).join('\n\n'),
                        },
                    ],
                };
            }
            case 'skill_create': {
                const skillId = await skills.createSkill({
                    name: args?.name,
                    description: args?.description,
                    signature: { inputs: {}, outputs: {} },
                    code: args?.code || '',
                    successRate: args?.success_rate || 0.0,
                    uses: 0,
                    avgReward: 0.0,
                    avgLatencyMs: 0.0,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Created skill #${skillId}: ${args?.name}`,
                        },
                    ],
                };
            }
            case 'skill_search': {
                const foundSkills = await skills.searchSkills({
                    task: args?.task,
                    k: args?.k || 10,
                    minSuccessRate: args?.min_success_rate || 0.0,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ” Found ${foundSkills.length} skills:\n\n` +
                                foundSkills.map((skill, i) => `${i + 1}. ${skill.name}\n   ${skill.description}\n   Success: ${(skill.successRate * 100).toFixed(1)}%`).join('\n\n'),
                        },
                    ],
                };
            }
            case 'causal_add_edge': {
                const cause = args?.cause;
                const effect = args?.effect;
                const uplift = args?.uplift;
                const confidence = args?.confidence || 0.95;
                const sampleSize = args?.sample_size || 0;
                const edgeId = causalGraph.addCausalEdge({
                    fromMemoryId: 0,
                    fromMemoryType: cause,
                    toMemoryId: 0,
                    toMemoryType: effect,
                    similarity: 0,
                    uplift,
                    confidence,
                    sampleSize,
                    evidenceIds: [],
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Added causal edge #${edgeId}\n${cause} â†’ ${effect}\nUplift: ${uplift}`,
                        },
                    ],
                };
            }
            case 'causal_query': {
                const cause = args?.cause;
                const effect = args?.effect;
                const minConfidence = args?.min_confidence || 0.5;
                const minUplift = args?.min_uplift || 0.0;
                const limit = args?.limit || 10;
                const edges = causalGraph.queryCausalEffects({
                    interventionMemoryId: 0,
                    interventionMemoryType: cause || '',
                    outcomeMemoryId: effect ? 0 : undefined,
                    minConfidence,
                    minUplift,
                });
                const limited = edges.slice(0, limit);
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ” Found ${edges.length} causal edges:\n\n` +
                                limited.map((edge, i) => `${i + 1}. ${edge.fromMemoryType} â†’ ${edge.toMemoryType}\n   Uplift: ${(edge.uplift || 0).toFixed(3)} (confidence: ${edge.confidence.toFixed(2)})`).join('\n\n'),
                        },
                    ],
                };
            }
            case 'recall_with_certificate': {
                const query = args?.query;
                const k = args?.k || 12;
                const result = await causalRecall.recall('mcp-' + Date.now(), query, k, undefined, 'internal');
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ” Retrieved ${result.candidates.length} results:\n\n` +
                                result.candidates.slice(0, 5).map((r, i) => `${i + 1}. ${r.type} ${r.id}\n   Similarity: ${r.similarity.toFixed(3)}\n   Uplift: ${r.uplift?.toFixed(3) || '0.000'}`).join('\n\n') +
                                `\n\nðŸ“œ Certificate ID: ${result.certificate.id}`,
                        },
                    ],
                };
            }
            case 'learner_discover': {
                const minAttempts = args?.min_attempts || 3;
                const minSuccessRate = args?.min_success_rate || 0.6;
                const minConfidence = args?.min_confidence || 0.7;
                const dryRun = args?.dry_run || false;
                const discovered = await learner.discover({
                    minAttempts,
                    minSuccessRate,
                    minConfidence,
                    dryRun,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸŒ™ Discovered ${discovered.length} causal patterns:\n\n` +
                                discovered.slice(0, 10).map((edge, i) => `${i + 1}. ${edge.fromMemoryType} â†’ ${edge.toMemoryType}\n   Uplift: ${(edge.uplift || 0).toFixed(3)} (n=${edge.sampleSize || 0})`).join('\n\n'),
                        },
                    ],
                };
            }
            case 'db_stats': {
                const stats = {
                    causal_edges: db.prepare('SELECT COUNT(*) as count FROM causal_edges').get()?.count || 0,
                    causal_experiments: db.prepare('SELECT COUNT(*) as count FROM causal_experiments').get()?.count || 0,
                    causal_observations: db.prepare('SELECT COUNT(*) as count FROM causal_observations').get()?.count || 0,
                    episodes: db.prepare('SELECT COUNT(*) as count FROM episodes').get()?.count || 0,
                    episode_embeddings: db.prepare('SELECT COUNT(*) as count FROM episode_embeddings').get()?.count || 0,
                    skills: db.prepare('SELECT COUNT(*) as count FROM skills').get()?.count || 0,
                };
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ“Š Database Statistics:\n\n` +
                                `Causal Edges: ${stats.causal_edges}\n` +
                                `Experiments: ${stats.causal_experiments}\n` +
                                `Observations: ${stats.causal_observations}\n` +
                                `Episodes (Vectors): ${stats.episodes}\n` +
                                `Episode Embeddings: ${stats.episode_embeddings}\n` +
                                `Skills: ${stats.skills}`,
                        },
                    ],
                };
            }
            // ======================================================================
            // CORE AGENTDB TOOLS (6-10)
            // ======================================================================
            case 'agentdb_stats': {
                const detailed = args?.detailed || false;
                // Helper to safely query table count
                const safeCount = (tableName) => {
                    try {
                        return db.prepare(`SELECT COUNT(*) as count FROM ${tableName}`).get()?.count || 0;
                    }
                    catch {
                        return 0; // Table doesn't exist
                    }
                };
                const stats = {
                    causal_edges: safeCount('causal_edges'),
                    causal_experiments: safeCount('causal_experiments'),
                    causal_observations: safeCount('causal_observations'),
                    episodes: safeCount('episodes'),
                    episode_embeddings: safeCount('episode_embeddings'),
                    skills: safeCount('skills'),
                    skill_embeddings: safeCount('skill_embeddings'),
                    reasoning_patterns: safeCount('reasoning_patterns'),
                    pattern_embeddings: safeCount('pattern_embeddings'),
                    learning_sessions: safeCount('rl_sessions'),
                };
                let output = `ðŸ“Š AgentDB Comprehensive Statistics\n\n` +
                    `ðŸ§  Memory & Learning:\n` +
                    `   Episodes (Vectors): ${stats.episodes}\n` +
                    `   Episode Embeddings: ${stats.episode_embeddings}\n` +
                    `   Skills: ${stats.skills}\n` +
                    `   Skill Embeddings: ${stats.skill_embeddings}\n` +
                    `   Reasoning Patterns: ${stats.reasoning_patterns}\n` +
                    `   Pattern Embeddings: ${stats.pattern_embeddings}\n` +
                    `   Learning Sessions: ${stats.learning_sessions}\n\n` +
                    `ðŸ”— Causal Intelligence:\n` +
                    `   Causal Edges: ${stats.causal_edges}\n` +
                    `   Experiments: ${stats.causal_experiments}\n` +
                    `   Observations: ${stats.causal_observations}\n`;
                if (detailed) {
                    // Add storage statistics
                    const dbStats = db.prepare(`
            SELECT page_count * page_size as total_bytes
            FROM pragma_page_count(), pragma_page_size()
          `).get();
                    const totalMB = (dbStats.total_bytes / (1024 * 1024)).toFixed(2);
                    // Add recent activity stats
                    const recentActivity = db.prepare(`
            SELECT COUNT(*) as count
            FROM episodes
            WHERE ts >= strftime('%s', 'now', '-7 days')
          `).get();
                    output += `\nðŸ“¦ Storage:\n` +
                        `   Database Size: ${totalMB} MB\n` +
                        `   Recent Activity (7d): ${recentActivity.count} episodes\n`;
                }
                return {
                    content: [
                        {
                            type: 'text',
                            text: output,
                        },
                    ],
                };
            }
            case 'agentdb_pattern_store': {
                const taskType = args?.taskType;
                const approach = args?.approach;
                const successRate = args?.successRate;
                const tags = args?.tags || [];
                const metadata = args?.metadata || {};
                const patternId = await reasoningBank.storePattern({
                    taskType,
                    approach,
                    successRate,
                    tags,
                    metadata,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Reasoning pattern stored successfully!\n\n` +
                                `ðŸ†” Pattern ID: ${patternId}\n` +
                                `ðŸ“‹ Task Type: ${taskType}\n` +
                                `ðŸ’¡ Approach: ${approach.substring(0, 100)}${approach.length > 100 ? '...' : ''}\n` +
                                `ðŸ“Š Success Rate: ${(successRate * 100).toFixed(1)}%\n` +
                                `ðŸ·ï¸  Tags: ${tags.join(', ') || 'none'}\n` +
                                `ðŸ§  Embedding generated and stored`,
                        },
                    ],
                };
            }
            case 'agentdb_pattern_search': {
                const task = args?.task;
                const k = args?.k || 10;
                const threshold = args?.threshold || 0.0;
                const filters = args?.filters;
                // Generate embedding for the task
                const taskEmbedding = await embeddingService.embed(task);
                const patterns = await reasoningBank.searchPatterns({
                    taskEmbedding,
                    k,
                    threshold,
                    filters: filters ? {
                        taskType: filters.taskType,
                        minSuccessRate: filters.minSuccessRate,
                        tags: filters.tags,
                    } : undefined,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ” Pattern search completed!\n\n` +
                                `ðŸ“Š Found: ${patterns.length} matching patterns\n` +
                                `ðŸŽ¯ Query: ${task}\n` +
                                `ðŸŽšï¸  Threshold: ${threshold.toFixed(2)}\n\n` +
                                `Top Results:\n` +
                                patterns.slice(0, 5).map((p, i) => `${i + 1}. [ID: ${p.id}] ${p.taskType}\n` +
                                    `   Similarity: ${(p.similarity || 0).toFixed(3)}\n` +
                                    `   Success Rate: ${(p.successRate * 100).toFixed(1)}%\n` +
                                    `   Approach: ${p.approach.substring(0, 80)}${p.approach.length > 80 ? '...' : ''}\n` +
                                    `   Uses: ${p.uses || 0}`).join('\n\n') +
                                (patterns.length > 5 ? `\n\n... and ${patterns.length - 5} more patterns` : ''),
                        },
                    ],
                };
            }
            case 'agentdb_pattern_stats': {
                const stats = reasoningBank.getPatternStats();
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ“Š Reasoning Pattern Statistics\n\n` +
                                `ðŸ“ˆ Overview:\n` +
                                `   Total Patterns: ${stats.totalPatterns}\n` +
                                `   Avg Success Rate: ${(stats.avgSuccessRate * 100).toFixed(1)}%\n` +
                                `   Avg Uses per Pattern: ${stats.avgUses.toFixed(1)}\n` +
                                `   High Performing (â‰¥80%): ${stats.highPerformingPatterns}\n` +
                                `   Recent (7 days): ${stats.recentPatterns}\n\n` +
                                `ðŸ† Top Task Types:\n` +
                                stats.topTaskTypes.slice(0, 10).map((tt, i) => `   ${i + 1}. ${tt.taskType}: ${tt.count} patterns`).join('\n') +
                                (stats.topTaskTypes.length === 0 ? '   No patterns stored yet' : ''),
                        },
                    ],
                };
            }
            case 'agentdb_clear_cache': {
                const cacheType = args?.cache_type || 'all';
                switch (cacheType) {
                    case 'patterns':
                    case 'stats':
                    case 'all':
                        reasoningBank.clearCache();
                        break;
                }
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Cache cleared successfully!\n\n` +
                                `ðŸ§¹ Cache Type: ${cacheType}\n` +
                                `â™»ï¸  Statistics and search results will be refreshed on next query`,
                        },
                    ],
                };
            }
            // ======================================================================
            // LEARNING SYSTEM TOOLS (Tools 1-5)
            // ======================================================================
            case 'learning_start_session': {
                const userId = args?.user_id;
                const sessionType = args?.session_type;
                const config = args?.config;
                const sessionId = await learningSystem.startSession(userId, sessionType, {
                    learningRate: config.learning_rate,
                    discountFactor: config.discount_factor,
                    explorationRate: config.exploration_rate,
                    batchSize: config.batch_size,
                    targetUpdateFrequency: config.target_update_frequency,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Learning session started!\n\n` +
                                `ðŸ†” Session ID: ${sessionId}\n` +
                                `ðŸ‘¤ User: ${userId}\n` +
                                `ðŸ§  Algorithm: ${sessionType}\n` +
                                `âš™ï¸  Config:\n` +
                                `   â€¢ Learning Rate: ${config.learning_rate}\n` +
                                `   â€¢ Discount Factor: ${config.discount_factor}\n` +
                                `   â€¢ Exploration Rate: ${config.exploration_rate || 0.1}\n` +
                                `   â€¢ Batch Size: ${config.batch_size || 32}\n\n` +
                                `ðŸ“ Use this session ID for predictions and feedback.`,
                        },
                    ],
                };
            }
            case 'learning_end_session': {
                const sessionId = args?.session_id;
                await learningSystem.endSession(sessionId);
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Learning session ended!\n\n` +
                                `ðŸ†” Session ID: ${sessionId}\n` +
                                `ðŸ’¾ Final policy saved to database\n` +
                                `ðŸ“Š Session marked as completed`,
                        },
                    ],
                };
            }
            case 'learning_predict': {
                const sessionId = args?.session_id;
                const state = args?.state;
                const prediction = await learningSystem.predict(sessionId, state);
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸŽ¯ AI Recommendation:\n\n` +
                                `ðŸ“ State: ${state}\n` +
                                `âœ¨ Recommended Action: ${prediction.action}\n` +
                                `ðŸ’¯ Confidence: ${(prediction.confidence * 100).toFixed(1)}%\n` +
                                `ðŸ“Š Q-Value: ${prediction.qValue?.toFixed(3) || 'N/A'}\n\n` +
                                `ðŸ”„ Alternative Actions:\n` +
                                prediction.alternatives.map((alt, i) => `   ${i + 1}. ${alt.action} (${(alt.confidence * 100).toFixed(1)}% confidence)`).join('\n'),
                        },
                    ],
                };
            }
            case 'learning_feedback': {
                const sessionId = args?.session_id;
                const state = args?.state;
                const action = args?.action;
                const reward = args?.reward;
                const nextState = args?.next_state;
                const success = args?.success;
                await learningSystem.submitFeedback({
                    sessionId,
                    state,
                    action,
                    reward,
                    nextState,
                    success,
                    timestamp: Date.now(),
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Feedback recorded!\n\n` +
                                `ðŸ†” Session: ${sessionId}\n` +
                                `ðŸ“ State: ${state}\n` +
                                `ðŸŽ¬ Action: ${action}\n` +
                                `ðŸ† Reward: ${reward.toFixed(2)}\n` +
                                `${success ? 'âœ…' : 'âŒ'} Success: ${success}\n` +
                                `${nextState ? `âž¡ï¸  Next State: ${nextState}\n` : ''}` +
                                `ðŸ§  Policy updated incrementally`,
                        },
                    ],
                };
            }
            case 'learning_train': {
                const sessionId = args?.session_id;
                const epochs = args?.epochs || 50;
                const batchSize = args?.batch_size || 32;
                const learningRate = args?.learning_rate || 0.01;
                console.log(`ðŸŽ“ Training session ${sessionId}...`);
                const result = await learningSystem.train(sessionId, epochs, batchSize, learningRate);
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸŽ“ Training completed!\n\n` +
                                `ðŸ“Š Training Results:\n` +
                                `   â€¢ Epochs: ${result.epochsCompleted}\n` +
                                `   â€¢ Final Loss: ${result.finalLoss.toFixed(4)}\n` +
                                `   â€¢ Avg Reward: ${result.avgReward.toFixed(3)}\n` +
                                `   â€¢ Convergence Rate: ${(result.convergenceRate * 100).toFixed(1)}%\n` +
                                `   â€¢ Training Time: ${result.trainingTimeMs}ms\n\n` +
                                `ðŸ’¾ Trained policy saved to database\n` +
                                `âœ¨ Ready for improved predictions!`,
                        },
                    ],
                };
            }
            // ======================================================================
            // LEARNING SYSTEM TOOLS (v1.4.0 - Tools 6-10) - IMPLEMENTATIONS
            // ======================================================================
            case 'learning_metrics': {
                const sessionId = args?.session_id;
                const timeWindowDays = args?.time_window_days || 7;
                const includeTrends = args?.include_trends !== false;
                const groupBy = args?.group_by || 'task';
                const metrics = await learningSystem.getMetrics({
                    sessionId,
                    timeWindowDays,
                    includeTrends,
                    groupBy,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ“Š Learning Performance Metrics\n\n` +
                                `â±ï¸  Time Window: ${timeWindowDays} days\n\n` +
                                `ðŸ“ˆ Overall Performance:\n` +
                                `   â€¢ Total Episodes: ${metrics.overall.totalEpisodes}\n` +
                                `   â€¢ Success Rate: ${(metrics.overall.successRate * 100).toFixed(1)}%\n` +
                                `   â€¢ Avg Reward: ${metrics.overall.avgReward.toFixed(3)}\n` +
                                `   â€¢ Reward Range: [${metrics.overall.minReward.toFixed(2)}, ${metrics.overall.maxReward.toFixed(2)}]\n` +
                                `   â€¢ Avg Latency: ${metrics.overall.avgLatencyMs.toFixed(0)}ms\n\n` +
                                `ðŸŽ¯ Top ${groupBy.charAt(0).toUpperCase() + groupBy.slice(1)}s:\n` +
                                metrics.groupedMetrics.slice(0, 5).map((g, i) => `   ${i + 1}. ${g.key.substring(0, 40)}${g.key.length > 40 ? '...' : ''}\n` +
                                    `      Count: ${g.count}, Success: ${(g.successRate * 100).toFixed(1)}%, Reward: ${g.avgReward.toFixed(2)}`).join('\n') +
                                (metrics.groupedMetrics.length === 0 ? '   No data available' : '') +
                                (includeTrends && metrics.trends.length > 0 ? `\n\nðŸ“‰ Recent Trends (last ${Math.min(7, metrics.trends.length)} days):\n` +
                                    metrics.trends.slice(-7).map((t) => `   ${t.date}: ${t.count} episodes, ${(t.successRate * 100).toFixed(1)}% success`).join('\n') : '') +
                                (metrics.policyImprovement.versions > 0 ? `\n\nðŸ§  Policy Improvement:\n` +
                                    `   â€¢ Versions: ${metrics.policyImprovement.versions}\n` +
                                    `   â€¢ Q-Value Improvement: ${metrics.policyImprovement.qValueImprovement >= 0 ? '+' : ''}${metrics.policyImprovement.qValueImprovement.toFixed(3)}` : ''),
                        },
                    ],
                };
            }
            case 'learning_transfer': {
                const sourceSession = args?.source_session;
                const targetSession = args?.target_session;
                const sourceTask = args?.source_task;
                const targetTask = args?.target_task;
                const minSimilarity = args?.min_similarity || 0.7;
                const transferType = args?.transfer_type || 'all';
                const maxTransfers = args?.max_transfers || 10;
                const result = await learningSystem.transferLearning({
                    sourceSession,
                    targetSession,
                    sourceTask,
                    targetTask,
                    minSimilarity,
                    transferType,
                    maxTransfers,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ”„ Learning Transfer Completed!\n\n` +
                                `ðŸ“¤ Source: ${sourceSession ? `Session ${sourceSession}` : `Task "${sourceTask}"`}\n` +
                                `ðŸ“¥ Target: ${targetSession ? `Session ${targetSession}` : `Task "${targetTask}"`}\n` +
                                `ðŸŽ¯ Transfer Type: ${transferType}\n` +
                                `ðŸ“Š Min Similarity: ${(minSimilarity * 100).toFixed(0)}%\n\n` +
                                `âœ… Transferred:\n` +
                                `   â€¢ Episodes: ${result.transferred.episodes}\n` +
                                `   â€¢ Skills/Q-Values: ${result.transferred.skills}\n` +
                                `   â€¢ Causal Edges: ${result.transferred.causalEdges}\n` +
                                (result.transferred.details.length > 0 ? `\nðŸ“ Transfer Details:\n` +
                                    result.transferred.details.slice(0, 5).map((d, i) => `   ${i + 1}. ${d.type} #${d.id} (similarity: ${(d.similarity * 100).toFixed(1)}%)`).join('\n') : '') +
                                `\n\nðŸ’¡ Knowledge successfully transferred for reuse!`,
                        },
                    ],
                };
            }
            case 'learning_explain': {
                const query = args?.query;
                const k = args?.k || 5;
                const explainDepth = args?.explain_depth || 'detailed';
                const includeConfidence = args?.include_confidence !== false;
                const includeEvidence = args?.include_evidence !== false;
                const includeCausal = args?.include_causal !== false;
                const explanation = await learningSystem.explainAction({
                    query,
                    k,
                    explainDepth,
                    includeConfidence,
                    includeEvidence,
                    includeCausal,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸ” AI Action Recommendations (Explainable)\n\n` +
                                `ðŸŽ¯ Query: ${query}\n\n` +
                                `ðŸ’¡ Recommended Actions:\n` +
                                explanation.recommendations.map((rec, i) => `${i + 1}. ${rec.action}\n` +
                                    `   â€¢ Confidence: ${(rec.confidence * 100).toFixed(1)}%\n` +
                                    `   â€¢ Success Rate: ${(rec.successRate * 100).toFixed(1)}%\n` +
                                    `   â€¢ Avg Reward: ${rec.avgReward.toFixed(3)}\n` +
                                    `   â€¢ Supporting Examples: ${rec.supportingExamples}\n` +
                                    (includeEvidence && rec.evidence ? `   â€¢ Evidence:\n` +
                                        rec.evidence.map((e) => `     - Episode ${e.episodeId}: reward=${e.reward.toFixed(2)}, similarity=${(e.similarity * 100).toFixed(1)}%`).join('\n') : '')).join('\n\n') +
                                (explainDepth !== 'summary' && explanation.reasoning ? `\n\nðŸ§  Reasoning:\n` +
                                    `   â€¢ Similar Experiences Found: ${explanation.reasoning.similarExperiencesFound}\n` +
                                    `   â€¢ Avg Similarity: ${(explanation.reasoning.avgSimilarity * 100).toFixed(1)}%\n` +
                                    `   â€¢ Unique Actions Considered: ${explanation.reasoning.uniqueActions}` : '') +
                                (includeCausal && explanation.causalChains && explanation.causalChains.length > 0 ? `\n\nðŸ”— Causal Reasoning Chains:\n` +
                                    explanation.causalChains.slice(0, 3).map((chain, i) => `   ${i + 1}. ${chain.fromMemoryType} â†’ ${chain.toMemoryType} (uplift: ${(chain.uplift || 0).toFixed(3)})`).join('\n') : ''),
                        },
                    ],
                };
            }
            case 'experience_record': {
                const sessionId = args?.session_id;
                const toolName = args?.tool_name;
                const action = args?.action;
                const stateBefore = args?.state_before;
                const stateAfter = args?.state_after;
                const outcome = args?.outcome;
                const reward = args?.reward;
                const success = args?.success;
                const latencyMs = args?.latency_ms;
                const metadata = args?.metadata;
                const experienceId = await learningSystem.recordExperience({
                    sessionId,
                    toolName,
                    action,
                    stateBefore,
                    stateAfter,
                    outcome,
                    reward,
                    success,
                    latencyMs,
                    metadata,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `âœ… Experience recorded successfully!\n\n` +
                                `ðŸ†” Experience ID: ${experienceId}\n` +
                                `ðŸ“‹ Session: ${sessionId}\n` +
                                `ðŸ”§ Tool: ${toolName}\n` +
                                `ðŸŽ¬ Action: ${action}\n` +
                                `ðŸ“Š Outcome: ${outcome}\n` +
                                `ðŸ† Reward: ${reward.toFixed(3)}\n` +
                                `${success ? 'âœ…' : 'âŒ'} Success: ${success}\n` +
                                (latencyMs ? `â±ï¸  Latency: ${latencyMs}ms\n` : '') +
                                `\nðŸ’¾ Experience stored for offline learning and future recommendations`,
                        },
                    ],
                };
            }
            case 'reward_signal': {
                const episodeId = args?.episode_id;
                const success = args?.success;
                const targetAchieved = args?.target_achieved !== false;
                const efficiencyScore = args?.efficiency_score || 0.5;
                const qualityScore = args?.quality_score || 0.5;
                const timeTakenMs = args?.time_taken_ms;
                const expectedTimeMs = args?.expected_time_ms;
                const includeCausal = args?.include_causal !== false;
                const rewardFunction = args?.reward_function || 'standard';
                const reward = learningSystem.calculateReward({
                    episodeId,
                    success,
                    targetAchieved,
                    efficiencyScore,
                    qualityScore,
                    timeTakenMs,
                    expectedTimeMs,
                    includeCausal,
                    rewardFunction,
                });
                return {
                    content: [
                        {
                            type: 'text',
                            text: `ðŸŽ¯ Reward Signal Calculated\n\n` +
                                `ðŸ“Š Final Reward: ${reward.toFixed(3)}\n` +
                                `ðŸ”§ Reward Function: ${rewardFunction}\n\n` +
                                `ðŸ“ˆ Input Factors:\n` +
                                `   â€¢ Success: ${success ? 'âœ…' : 'âŒ'}\n` +
                                `   â€¢ Target Achieved: ${targetAchieved ? 'âœ…' : 'âŒ'}\n` +
                                `   â€¢ Efficiency Score: ${(efficiencyScore * 100).toFixed(1)}%\n` +
                                `   â€¢ Quality Score: ${(qualityScore * 100).toFixed(1)}%\n` +
                                (timeTakenMs && expectedTimeMs ? `   â€¢ Time Efficiency: ${((expectedTimeMs / timeTakenMs) * 100).toFixed(1)}%\n` : '') +
                                (includeCausal ? `   â€¢ Causal Impact: Included\n` : '') +
                                `\nðŸ’¡ Use this reward signal for learning feedback`,
                        },
                    ],
                };
            }
            default:
                throw new Error(`Unknown tool: ${name}`);
        }
    }
    catch (error) {
        return {
            content: [
                {
                    type: 'text',
                    text: `âŒ Error: ${error.message}\n${error.stack || ''}`,
                },
            ],
            isError: true,
        };
    }
});
// ============================================================================
// Start Server
// ============================================================================
async function main() {
    const transport = new StdioServerTransport();
    await server.connect(transport);
    console.error('ðŸš€ AgentDB MCP Server v1.3.0 running on stdio');
    console.error('ðŸ“¦ 29 tools available (5 core vector DB + 9 frontier + 10 learning + 5 AgentDB tools)');
    console.error('ðŸ§  Embedding service initialized');
    console.error('ðŸŽ“ Learning system ready (9 RL algorithms)');
    console.error('âœ¨ New learning tools: metrics, transfer, explain, experience_record, reward_signal');
    console.error('ðŸ”¬ Extended features: transfer learning, XAI explanations, reward shaping');
    // Keep the process alive - the StdioServerTransport handles stdin/stdout
    // but we need to ensure Node.js doesn't exit when main() completes
    // Use setInterval to keep event loop alive (like many MCP servers do)
    // This ensures the process doesn't exit even if stdin closes
    const keepAlive = setInterval(() => {
        // Empty interval just to keep event loop alive
    }, 1000 * 60 * 60); // Every hour (basically forever)
    // Handle graceful shutdown
    const shutdown = () => {
        clearInterval(keepAlive);
        process.exit(0);
    };
    process.on('SIGINT', shutdown);
    process.on('SIGTERM', shutdown);
    // Return a never-resolving promise
    return new Promise(() => {
        // The setInterval above keeps the event loop alive
        // StdioServerTransport handles all MCP communication
    });
}
main().catch(console.error);
//# sourceMappingURL=agentdb-mcp-server.js.map