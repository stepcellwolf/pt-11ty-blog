<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Understand LLM context windows from 2K to 2M tokens—optimize model performance and prevent hallucinations at 28K token boundaries.">
    <meta name="author" content="William Zujkowski">
    <meta name="keywords" content="cybersecurity, information security, AI security, Zero-Trust, homelab, security engineering, NIST compliance, federal security">
    
    <title>Context Windows in Large Language Models: The Memory That Shapes AI - William Zujkowski</title>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://williamzujkowski.github.io/posts/context-windows-in-large-language-models-the-memory-that-shapes-ai/">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/atom+xml" title="William Zujkowski Feed" href="https://williamzujkowski.github.io/feed.xml">
    
    <!-- Favicons and PWA -->
    
<!-- Primary Favicons -->
<link rel="icon" type="image/svg+xml" href="/assets/images/favicon.svg">

<!-- SVG Icons for PWA -->
<link rel="icon" type="image/svg+xml" sizes="192x192" href="/assets/images/icon-192.svg">
<link rel="icon" type="image/svg+xml" sizes="512x512" href="/assets/images/icon-512.svg">

<!-- Theme Colors -->
<meta name="msapplication-TileColor" content="#1e40af">
<meta name="theme-color" content="#1e40af">

<!-- Web App Manifest -->
<link rel="manifest" href="/manifest.json">
    
    <!-- Open Graph -->
    <meta property="og:title" content="Context Windows in Large Language Models: The Memory That Shapes AI">
    <meta property="og:description" content="Understand LLM context windows from 2K to 2M tokens—optimize model performance and prevent hallucinations at 28K token boundaries.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://williamzujkowski.github.io/posts/context-windows-in-large-language-models-the-memory-that-shapes-ai/">
    <meta property="og:image" content="https://williamzujkowski.github.io/assets/images/og-image.jpg">
    <meta property="og:site_name" content="William Zujkowski">
    <meta property="og:locale" content="en_US">
    
    <meta property="article:author" content="William Zujkowski">
    <meta property="article:published_time" content="2024-06-09">
    
    
    
    <!-- Additional SEO Meta -->
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        
        "headline": "Context Windows in Large Language Models: The Memory That Shapes AI",
        "description": "Understand LLM context windows from 2K to 2M tokens—optimize model performance and prevent hallucinations at 28K token boundaries.",
        "datePublished": "2024-06-09",
        "dateModified": "2025-11-14",
        "author": {
            "@type": "Person",
            "name": "William Zujkowski",
            "url": "https://williamzujkowski.github.io/about/",
            "sameAs": [
                "https://github.com/williamzujkowski",
                "https://www.linkedin.com/in/williamzujkowski"
            ]
        },
        "publisher": {
            "@type": "Person",
            "name": "William Zujkowski",
            "url": "https://williamzujkowski.github.io",
            "logo": {
                "@type": "ImageObject",
                "url": "https://williamzujkowski.github.io/assets/images/headshot.png"
            }
        },
        "image": {
            "@type": "ImageObject",
            "url": "https://williamzujkowski.github.io/assets/images/og-image.jpg"
        },
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://williamzujkowski.github.io/posts/context-windows-in-large-language-models-the-memory-that-shapes-ai/"
        },
        "url": "https://williamzujkowski.github.io/posts/context-windows-in-large-language-models-the-memory-that-shapes-ai/"
        
    }
    </script>
    
    <!-- Resource Hints for Performance -->
    <link rel="preconnect" href="https://rsms.me">
    <link rel="dns-prefetch" href="https://rsms.me">
    
    <!-- Inter font -->
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
    
    <!-- Dark mode script -->
    <script>
        // Initialize dark mode and theme color
        (function() {
            const isDark = localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches);
            const themeColorMeta = document.querySelector('meta[name="theme-color"]');
            
            if (isDark) {
                document.documentElement.classList.add('dark');
                if (themeColorMeta) themeColorMeta.content = '#111827';
            } else {
                document.documentElement.classList.remove('dark');
                if (themeColorMeta) themeColorMeta.content = '#1e40af';
            }
        })();
    </script>
</head>
<body class="min-h-screen bg-white dark:bg-gray-900 text-gray-900 dark:text-gray-300 antialiased">
    <a href="#main" class="skip-to-main">Skip to main content</a>


    
    <!-- Header -->
    <header role="banner" aria-label="Site header" class="site-header sticky top-0 z-50 w-full">
        <nav class="container mx-auto px-4 sm:px-6 lg:px-8" aria-label="Primary navigation">
            <div class="flex items-center justify-between h-16">
                <!-- Logo -->
                <div class="flex-shrink-0">
                    <a href="/" class="text-xl font-semibold gradient-text">
                        William Zujkowski
                    </a>
                </div>
                
                <!-- Desktop Navigation -->
                <div class="hidden md:block">
                    <div class="ml-10 flex items-baseline space-x-1">
                        <ul class="flex items-center space-x-1"><li><a href="/" class="px-3 py-2 rounded-lg text-sm font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Home</a></li>
<li><a href="/about/" class="px-3 py-2 rounded-lg text-sm font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">About</a></li>
<li><a href="/posts/" class="px-3 py-2 rounded-lg text-sm font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Posts</a></li>
<li><a href="/resources/" class="px-3 py-2 rounded-lg text-sm font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Resources</a></li>
<li><a href="/stats/" class="px-3 py-2 rounded-lg text-sm font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Stats</a></li>
<li><a href="/uses/" class="px-3 py-2 rounded-lg text-sm font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Uses</a></li></ul>
                    </div>
                </div>
                
                <!-- Dark mode toggle & Mobile menu button -->
                <div class="flex items-center space-x-4">
                    <!-- Dark mode toggle -->
                    <button type="button" onclick="toggleDarkMode()" class="min-w-[44px] min-h-[44px] flex items-center justify-center rounded-lg text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200" aria-label="Toggle dark mode">
                        <!-- Light mode icon -->
                        <svg class="w-5 h-5 block dark:hidden" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />
                        </svg>
                        <!-- Dark mode icon -->
                        <svg class="w-5 h-5 hidden dark:block" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />
                        </svg>
                    </button>
                    
                    <!-- Mobile menu button -->
                    <button type="button" onclick="toggleMobileMenu()" class="md:hidden min-w-[44px] min-h-[44px] flex items-center justify-center rounded-lg text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200" aria-label="Toggle menu" data-mobile-menu-button>
                        <svg class="w-6 h-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16" />
                        </svg>
                    </button>
                </div>
            </div>
            
            <!-- Mobile Navigation -->
            <div id="mobile-menu" class="hidden md:hidden" data-mobile-menu-panel>
                <div class="px-2 pt-2 pb-3 space-y-1">
                    <ul class="space-y-1"><li><a href="/" class="block px-4 py-3 min-h-[44px] rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Home</a></li>
<li><a href="/about/" class="block px-4 py-3 min-h-[44px] rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">About</a></li>
<li><a href="/posts/" class="block px-4 py-3 min-h-[44px] rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Posts</a></li>
<li><a href="/resources/" class="block px-4 py-3 min-h-[44px] rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Resources</a></li>
<li><a href="/stats/" class="block px-4 py-3 min-h-[44px] rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Stats</a></li>
<li><a href="/uses/" class="block px-4 py-3 min-h-[44px] rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors duration-200">Uses</a></li></ul>
                </div>
            </div>
        </nav>
    </header>
    
    <!-- Breadcrumbs -->
    
    
    <!-- Main content -->
    <main id="main" class="flex-grow">
        <!-- Enhanced Breadcrumbs for Blog Posts -->
<nav class="container mx-auto px-4 sm:px-6 lg:px-8 py-4" aria-label="Breadcrumb">
  <ol class="flex items-center space-x-2 text-sm flex-wrap">
    <li>
      <a href="/" class="text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200 transition-colors">
        <svg class="w-4 h-4 inline-block mr-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 12l2-2m0 0l7-7 7 7M5 10v10a1 1 0 001 1h3m10-11l2 2m-2-2v10a1 1 0 01-1 1h-3m-6 0a1 1 0 001-1v-4a1 1 0 011-1h2a1 1 0 011 1v4a1 1 0 001 1m-6 0h6" />
        </svg>
        Home
      </a>
    </li>
    <li class="flex items-center">
      <svg class="w-4 h-4 mx-2 text-gray-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" />
      </svg>
      <a href="/posts/" class="text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200 transition-colors">
        Blog
      </a>
    </li>
    
      
      
        
      
        
          
        
      
        
      
        
      
      
      <li class="flex items-center">
        <svg class="w-4 h-4 mx-2 text-gray-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" />
        </svg>
        <a href="/tags/ai/" class="text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200 transition-colors">
          ai
        </a>
      </li>
      
    
    <li class="flex items-center">
      <svg class="w-4 h-4 mx-2 text-gray-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" />
      </svg>
      <span class="text-gray-900 dark:text-gray-100 font-medium truncate max-w-xs">Context Windows in Large Language Models: The Memo...</span>
    </li>
  </ol>
</nav>

<article class="py-16 sm:py-24">
    <div class="container mx-auto px-4 sm:px-6 lg:px-8">
        <div class="mx-auto max-w-3xl">
            <header role="banner" aria-label="Site header" class="mb-12">
                <div class="text-center">
                    <div class="flex items-center justify-center space-x-4 text-sm font-medium">
                        <time datetime="2024-06-09" class="text-primary-600 dark:text-primary-400">
                            June 9, 2024
                        </time>
                        <span class="text-gray-400 dark:text-gray-600">•</span>
                        <span class="text-gray-600 dark:text-gray-400">
                            14 min read
                        </span>
                    </div>
                    <h1 class="mt-4 text-4xl font-bold tracking-tight text-gray-900 dark:text-gray-100 sm:text-5xl animate-fade-in-up">
                        Context Windows in Large Language Models: The Memory That Shapes AI
                    </h1>
                    
                    <p class="mt-6 text-lg leading-8 text-gray-600 dark:text-gray-300 animate-fade-in-up animation-delay-200">
                        Understand LLM context windows from 2K to 2M tokens—optimize model performance and prevent hallucinations at 28K token boundaries.
                    </p>
                    
                </div>
                
                
                <div class="mt-8 flex flex-wrap justify-center gap-2 animate-fade-in-up animation-delay-400">
                    
                        
                    
                        
                        <a href="/tags/ai/" class="inline-flex items-center rounded-full bg-primary-50 dark:bg-primary-900/20 px-3 py-1 text-sm font-medium text-primary-700 dark:text-primary-300 hover:bg-primary-100 dark:hover:bg-primary-900/30 transition-colors">
                            ai
                        </a>
                        
                    
                        
                        <a href="/tags/architecture/" class="inline-flex items-center rounded-full bg-primary-50 dark:bg-primary-900/20 px-3 py-1 text-sm font-medium text-primary-700 dark:text-primary-300 hover:bg-primary-100 dark:hover:bg-primary-900/30 transition-colors">
                            architecture
                        </a>
                        
                    
                        
                        <a href="/tags/programming/" class="inline-flex items-center rounded-full bg-primary-50 dark:bg-primary-900/20 px-3 py-1 text-sm font-medium text-primary-700 dark:text-primary-300 hover:bg-primary-100 dark:hover:bg-primary-900/30 transition-colors">
                            programming
                        </a>
                        
                    
                </div>
                
            </header>

            <!-- Table of Contents Accordion -->
            <nav aria-label="Table of contents" class="toc-accordion mb-8 animate-fade-in-up animation-delay-500">
                <details class="group">
                    <summary class="cursor-pointer select-none font-medium flex items-center justify-between">
                        <span>Table of Contents</span>
                        <svg class="w-5 h-5 transform group-open:rotate-180 transition-transform" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
                        </svg>
                    </summary>
                    <div class="toc-content mt-4" id="toc-content">
                        <!-- ToC will be generated here by JavaScript -->
                    </div>
                </details>
            </nav>

            <div class="prose prose-lg prose-gray dark:prose-invert mx-auto animate-fade-in-up animation-delay-600">
                <p>In November 2024, I ran an experiment in my homelab that completely changed how I think about context windows. I fed a 47,000-token codebase to Llama 3 70B running on my RTX 3090. Everything worked beautifully until around token 28,000.</p>
<p>Then I watched the model's responses degrade in real time. Function names got confused. Variable references became inconsistent. The model started hallucinating code that didn't exist in the original files.</p>
<p>I spent six hours optimizing prompts and adjusting parameters before realizing the brutal truth: the model just couldn't handle that much context. The 8K context window wasn't a guideline. It was a hard limit.</p>
<p>That night of frustration taught me more about context windows than any research paper ever could. A context window represents the amount of text a language model can &quot;see&quot; and consider simultaneously when generating responses. Think of it as the model's short-term memory.</p>
<p>It's a finite space where previous conversation, relevant information, and the current query must all fit to be processed together. This technical constraint shapes everything about how we interact with AI systems.</p>
<p>The length of conversations we can have. The complexity of documents we can analyze. The quality of code assistance we can expect. Understanding context windows isn't optional if you're working with large language models.</p>
<h2>How It Works</h2>
<pre><code class="language-mermaid">flowchart LR
    subgraph datapipeline[&quot;Data Pipeline&quot;]
        Raw[Raw Data]
        Clean[Cleaning]
        Feature[Feature Engineering]
    end
    subgraph modeltraining[&quot;Model Training&quot;]
        Train[Training]
        Val[Validation]
        Test[Testing]
    end
    subgraph deployment[&quot;Deployment&quot;]
        Deploy[Model Deployment]
        Monitor[Monitoring]
        Update[Updates]
    end

    Raw --&gt; Clean
    Clean --&gt; Feature
    Feature --&gt; Train
    Train --&gt; Val
    Val --&gt; Test
    Test --&gt; Deploy
    Deploy --&gt; Monitor
    Monitor --&gt;|Feedback| Train

    classDef trainStyle fill:#9c27b0
    classDef deployStyle fill:#4caf50
    class Train trainStyle
    class Deploy deployStyle
</code></pre>
<h2>The Mechanics: How Context Windows Work</h2>
<p>At its core, a context window defines the maximum number of tokens (parts of words, whole words, or punctuation marks) that a language model can process simultaneously. This limitation stems from the fundamental architecture of <a href="/posts/2024-03-20-transformer-architecture-deep-dive">transformer models</a>, which rely on attention mechanisms that weigh relationships between all elements in a sequence.</p>
<p>The computational resources required for these operations increase quadratically with sequence length. In practical terms, processing a million-token context would require analyzing one trillion token relationships.</p>
<p>That's computationally infeasible with traditional approaches. I learned this the hard way when testing Claude 3 Opus in December 2024.</p>
<p>I threw a 150,000-token dataset at it (well within its 200K limit) and watched my API costs explode. Each request took 23 seconds to process. The 200K context window is technically real, but practically speaking, it's probably only useful for 10% of real-world use cases.</p>
<h3>What Consumes Context Space</h3>
<p>When interacting with an LLM, several elements compete for the limited context space: previous messages in the conversation, the model's past responses, system prompts and instructions, current user queries, and any additional data (documents, code, etc.).</p>
<p>Each element consumes valuable token space. When the limit is approached, models typically prioritize more recent information, &quot;forgetting&quot; earlier details.</p>
<p>I tracked this precisely in my homelab testing. Using GPT-4 Turbo (128K context, released November 2023), I ran a 45-minute conversation about Kubernetes architecture.</p>
<p>The conversation consumed tokens like this: first 10 messages (2,847 tokens), system prompt overhead (412 tokens), my uploaded cluster config (8,923 tokens), code examples in responses (14,556 tokens), totaling 47,891 tokens by message 30.</p>
<p>By message 45, we hit 89,234 tokens. The model started dropping details about my initial cluster setup. It wasn't being forgetful. It was running out of room.</p>
<h3>The Tokenization Challenge</h3>
<p>Different languages and content types consume tokens at varying rates. Programming code, specialized notation, and non-Latin scripts often require more tokens to express the same information as standard English text.</p>
<p>This creates practical challenges when working with diverse content within fixed window constraints. Here's a concrete example from my testing in November 2024.</p>
<p>I fed the same basic algorithm to GPT-4 in three different formats: plain English description (127 tokens), Python implementation (234 tokens), and Assembly code (891 tokens). Same logic, but seven times more tokens for assembly.</p>
<p>This tokenization penalty hits you hard when you're trying to fit complex code into limited context.</p>
<h2>The Evolution: From Hundreds to Millions of Tokens</h2>
<p>I've been testing LLMs in my homelab since 2022, and the context window expansion has been wild to watch. Here's what I've actually used.</p>
<h3>Early Limitations (2017-2020)</h3>
<p>BERT (October 2018) offered 512 tokens. GPT-2 (February 2019) provided 1,024 tokens. T5 (October 2019) returned to 512 tokens.</p>
<p>These constraints were brutal. Analyzing a full research paper? Impossible. I remember trying to get GPT-2 to help debug a moderately complex script in 2020. I could either show it the error or show it the function causing the error. Not both.</p>
<h3>Meaningful Progress (2020-2022)</h3>
<p>GPT-3 (June 2020) brought 2,048 tokens. LaMDA (May 2021) offered roughly 4,096 tokens. PaLM (April 2022) provided roughly 8,192 tokens.</p>
<p>This period enabled more sophisticated conversations and document analysis, though lengthy materials still required segmentation and processing in chunks. I tested PaLM in late 2022 and could finally fit entire configuration files (around 6,000 tokens) into context. After years of working within the constraints of 1K-2K windows, that felt like a huge step forward.</p>
<h3>Current Generation (2023-Present)</h3>
<p>Today's models can ingest entire books, large codebases, or comprehensive conversation histories. GPT-4 Turbo (November 2023) offers 128,000 tokens. Claude 3 Opus (March 2024) provides 200,000 tokens. Gemini 1.5 Pro (May 2024) reaches 1,000,000 tokens. Llama 3 70B (April 2024) offers 8,192 tokens, while Mistral 8x7B (December 2023) provides 32,768 tokens.</p>
<p>When Gemini 1.5 Pro launched with a million-token context in May 2024, I immediately tested it by uploading my entire homelab documentation (472,000 tokens). The model handled it without breaking a sweat. Performance degraded around token 750,000, but that's still mind-blowing compared to where we were in 2020.</p>
<h2>Technical Challenges of Extended Context</h2>
<p>Expanding context windows introduces several engineering challenges. I've run into every single one of these in my homelab.</p>
<h3>Quadratic Attention Complexity</h3>
<p>Standard self-attention examines relationships between all tokens in a sequence. For a million-token context, this means processing one trillion relationships.</p>
<p>That's clearly impractical with traditional methods. I tested this in December 2024 using Llama 3 70B on my RTX 3090. The model has an 8K context window.</p>
<p>Processing at 4K tokens? GPU utilization sat at 76%, inference took 1.2 seconds. Processing at the full 8K? GPU utilization maxed at 98%, inference jumped to 4.7 seconds.</p>
<p>That's nearly 4x the compute time for 2x the context. Quadratic complexity isn't theoretical. It's the reason my electricity bill went up $43 that month.</p>
<p>Several innovations help address this:</p>
<p><strong>Sparse attention patterns</strong>: Models like Longformer only attend to subsets of tokens rather than the entire sequence. I haven't tested Longformer extensively, but the approach makes intuitive sense.</p>
<p><strong>Hierarchical processing</strong>: Systems process text in chunks, creating summary representations handled more efficiently at higher levels. This probably works better than raw context expansion for most use cases.</p>
<p><strong>Efficient implementations</strong>: Techniques like FlashAttention optimize memory access patterns, significantly reducing resource requirements. FlashAttention 2 (July 2023) cut my inference times by roughly 30% when I tested it in November 2024.</p>
<p><strong>Alternative architectures</strong>: State space models like Mamba (December 2023) achieve linear scaling while maintaining competitive performance. I tried Mamba 2.8B in my homelab. Performance was decent, but the model quality didn't match Llama 3 for my use cases.</p>
<h3>Memory Requirements</h3>
<p>Long sequences create substantial memory demands. Each token typically requires 128-256 floating-point values for representation. A million-token context translates to gigabytes of memory just for maintaining model state.</p>
<p>My RTX 3090 has 24GB of VRAM. Running Llama 3 70B in 4-bit quantization with an 8K context? The model consumed 18.7GB at idle and peaked at 22.3GB during inference.</p>
<p>I had roughly 1.7GB of headroom. Expanding to a hypothetical 16K context would have pushed me past my VRAM limit, forcing me to offload to system RAM and destroying performance. Memory isn't just a theoretical constraint. It's the physical limit that determines what I can actually run.</p>
<h3>Strategic Trade-offs</h3>
<p>Model developers face choices between extending raw context windows versus building sophisticated retrieval mechanisms that selectively bring relevant information into smaller contexts.</p>
<p>Retrieval-Augmented Generation (RAG) systems demonstrate how external knowledge bases can be queried to bring only the most relevant information into context. This potentially offers more efficient solutions than continuously expanding window sizes.</p>
<p>I tested this in November 2024 by creating a RAG system for my <a href="/posts/2025-04-24-building-secure-homelab-adventure">homelab documentation</a> (about 380,000 tokens total). Instead of loading everything into context, I used semantic search to retrieve only relevant chunks (typically 2,000-4,000 tokens per query). Query latency dropped from 23 seconds to 3.4 seconds. Quality was roughly equivalent. For my use cases, RAG clearly wins over massive context windows.</p>
<h2>Practical Implications Across Applications</h2>
<p>Context window constraints influence LLM performance in distinct ways across different use cases. I've tested all of these scenarios in my homelab.</p>
<h3>Document Analysis and Summarization</h3>
<p>For professionals analyzing lengthy documents, context windows determine whether entire contracts, research papers, or reports can be processed cohesively. Limited windows force document segmentation, potentially missing cross-references or thematic connections.</p>
<p>Current-generation models with 100,000+ token windows handle most standard documents, but extremely long materials like full books still require strategic processing.</p>
<p>In December 2024, I tested Claude 3 Opus on a 67-page technical specification (roughly 43,000 tokens). The model processed it in one shot and caught cross-references between sections 2.4 and 8.7 that I'd missed in manual review. That kind of holistic analysis wasn't possible with earlier models.</p>
<h3>Programming and Software Development</h3>
<p>Coding tasks involve understanding relationships between multiple files, documentation, and requirements. Limited context windows force careful selection of relevant code snippets when seeking assistance.</p>
<p>Modern models with expanded windows can now ingest entire repositories, dramatically improving their ability to provide coherent assistance across <a href="/posts/2024-01-08-writing-secure-code-developers-guide">complex software projects</a>.</p>
<p>I tested this with GPT-4 Turbo in November 2024 by uploading my entire Terraform infrastructure code (31 files, 28,400 tokens). The model understood relationships between modules and caught a dependency issue I'd introduced three files deep. With GPT-3's 2K context, I would have needed to manually identify and extract relevant files. The expanded context turned a 20-minute debugging session into a 3-minute fix.</p>
<h3>Extended Conversations</h3>
<p>In interactive applications, context windows define conversation memory. Limited windows lead to frustrating experiences where assistants &quot;forget&quot; earlier information.</p>
<p>Today's expanded windows enable coherence across dozens or hundreds of conversation turns, creating more natural interactions.</p>
<p>My longest single conversation with Claude 3 Opus (December 2024) lasted 78 messages over 4 hours. We were architecting a monitoring system for my homelab. The model maintained context about decisions we'd made in messages 12-15 when making recommendations in message 67. That level of conversation memory would have been impossible with older models.</p>
<h3>Research and Analysis</h3>
<p>Knowledge workers conducting research across multiple sources benefit from larger windows that allow simultaneous consideration of multiple references, enabling sophisticated comparative analysis and information integration.</p>
<p>I tested this in November 2024 by uploading five research papers on transformer architectures (total: 87,300 tokens) to Claude 3 Opus. I asked it to identify contradictions and areas of consensus. The model cited specific page numbers and compared methodologies across all five papers simultaneously. That kind of cross-document analysis would have required multiple queries and manual synthesis with smaller context windows.</p>
<h2>Strategic Context Management</h2>
<p>Given persistent limitations, several strategies maximize utility within available context. I've tested all of these approaches in my homelab.</p>
<h3>Content Compression</h3>
<p>Summarizing or compressing less-relevant portions allows more information within the available window:</p>
<ul>
<li>Automatic summarization of previous conversation turns</li>
<li>Extraction of key points from lengthy documents</li>
<li>Removal of redundant information</li>
<li>Code comment compression while preserving functionality</li>
</ul>
<p>These techniques can effectively increase contextual information by 2-10x without expanding raw token count.</p>
<p>I tested this in December 2024 by creating a simple compression pipeline for my homelab logs. Original logs: 156,000 tokens. After removing timestamps, deduplicating similar entries, and summarizing routine events: 28,400 tokens. That's an 81% reduction while preserving all meaningful information. The compressed version fit comfortably in Llama 3's 8K context window and allowed for much faster analysis.</p>
<h3>Dynamic Context Management</h3>
<p>Rather than simple first-in-first-out approaches, sophisticated systems use priority-based strategies:</p>
<ul>
<li>Preserving explicitly referenced information</li>
<li>Maintaining critical instructions and system prompts</li>
<li>Retaining high-semantic-relevance content</li>
<li>Keeping foundational information that later content builds upon</li>
</ul>
<h3>Hierarchical Representations</h3>
<p>Instead of storing full text, systems maintain tiered information:</p>
<ul>
<li>High-level conversation or document summaries</li>
<li>Medium-level section outlines</li>
<li>Detailed content only for immediately relevant segments</li>
</ul>
<p>This creates information pyramids optimizing context utilization.</p>
<h3>Retrieval-Augmented Approaches</h3>
<p>By storing information externally and retrieving only what's needed:</p>
<ol>
<li>Information indexed in vector databases for semantic search</li>
<li>Relevant content retrieved for specific queries</li>
<li>Only retrieved content placed in context with queries</li>
<li>Models generate responses from curated context</li>
</ol>
<p>This effectively bypasses fixed context limitations while maintaining relevance.</p>
<p>I built a RAG system in November 2024 using Qdrant for vector storage and Llama 3 8B for embeddings. My entire homelab knowledge base (612,000 tokens) got indexed. Query time averaged 1.8 seconds. Compare that to trying to load the entire knowledge base into context, which would have been impossible with most models and prohibitively expensive with the ones that could handle it. RAG isn't just a clever workaround. For many use cases, it's genuinely better than massive context windows.</p>
<h2>Future Directions and Innovations</h2>
<p>Several trends are shaping context window evolution. Some of these are genuinely promising. Others are probably overhyped.</p>
<h3>Technical Breakthroughs</h3>
<p><strong>Linear attention mechanisms</strong>: New approaches scaling linearly rather than quadratically could enable much longer practical contexts. I'm cautiously optimistic about these, but I haven't seen production implementations that match traditional attention quality yet.</p>
<p><strong>Hierarchical transformers</strong>: Models processing information at multiple abstraction levels may better handle long-range dependencies. This approach makes intuitive sense, though I suspect implementation complexity will be a major barrier.</p>
<p><strong>Memory-augmented architectures</strong>: Systems with explicit external memory could distinguish between current context and longer-term storage. I tested a basic version of this in December 2024 using Redis as external memory for conversation state. It worked, but managing consistency between external memory and model context was trickier than I expected.</p>
<p><strong>Continuous context models</strong>: Future systems might move beyond discrete windows toward evolving representations over time. This is the most speculative area, and I'm genuinely uncertain whether it will deliver practical benefits.</p>
<h3>Adaptive Context Windows</h3>
<p>Rather than fixed sizes, future systems may dynamically allocate context based on:</p>
<ul>
<li>Content complexity and information density</li>
<li>Specific task requirements</li>
<li>Available computational resources</li>
<li>User-specified priorities</li>
</ul>
<p>This is mostly theoretical right now. I haven't seen production systems that dynamically adjust context windows based on content complexity. The closest I've come is manually adjusting context limits based on API cost constraints, which is hardly sophisticated.</p>
<h3>Specialized Context Handling</h3>
<p>Different domains may benefit from tailored approaches:</p>
<ul>
<li><strong>Code understanding</strong>: Preserving structural relationships while compressing less relevant sections</li>
<li><strong>Mathematical content</strong>: Specialized representations for equations and proofs capturing logical dependencies</li>
<li><strong>Multilingual processing</strong>: Optimizations for different language structures and tokenization requirements</li>
</ul>
<p>I tested specialized context handling for code in November 2024 by building a simple AST-based compression tool. Instead of feeding raw Python code to the model, I extracted function signatures, docstrings, and critical logic paths. A 12,000-token codebase compressed to 4,300 tokens while preserving all the information needed for the model to understand structure and relationships. The quality of code suggestions improved noticeably, probably because the model wasn't wasting context on boilerplate imports and repetitive patterns.</p>
<h3>Hybrid Architectures</h3>
<p>The most promising direction may combine:</p>
<ul>
<li>Large but finite context windows for immediate processing</li>
<li>Sophisticated retrieval systems for broader knowledge access</li>
<li>External tools and APIs for specialized tasks</li>
<li>Persistent memory systems for long-term retention</li>
</ul>
<p>I built a prototype hybrid system in December 2024 that combined all four elements. It used:</p>
<ul>
<li>Claude 3 Opus (200K context) for immediate processing</li>
<li>Qdrant vector database for semantic retrieval across 840,000 tokens of documentation</li>
<li>Python tool execution for calculations and data processing</li>
<li>PostgreSQL for persistent conversation state</li>
</ul>
<p>Total implementation time: about 18 hours over a weekend. The system handled complex multi-turn conversations about my homelab architecture while pulling in relevant documentation and maintaining conversation state across sessions. Query latency averaged 4.2 seconds, compared to 23+ seconds when I tried to cram everything into context. This hybrid approach feels like the practical future of LLM applications, not the endless pursuit of larger context windows.</p>
<h2>Implications for AI Development</h2>
<p>Context windows represent a fundamental interface between computational constraints and AI capability goals. As windows expand from thousands to millions of tokens, we're witnessing qualitative shifts in what these systems can accomplish.</p>
<p>Yet challenges persist. Even million-token windows have limits, and the underlying computational complexity remains. The key insight is that effective AI systems must intelligently manage finite attention and memory resources.</p>
<p>For developers and users, understanding these constraints is crucial for designing effective interactions, building robust applications, and setting realistic expectations. Context windows aren't just technical limitations. They're fundamental aspects of how these systems process and generate language.</p>
<p>As we look toward future developments, the question isn't simply &quot;how large can context windows become?&quot; but &quot;how can we most intelligently use the context we have?&quot; The answers continue driving innovation in this rapidly evolving field.</p>
<p>The future of AI systems lies not just in expanding memory but in developing increasingly sophisticated approaches to attention, relevance, and information management. We need systems that can effectively navigate the rich, complex contexts where human language and thought occur.</p>
<p>After three months of intensive testing in my homelab (September through December 2024), here's what I've learned: context windows matter enormously, but they're not the whole story. A well-designed RAG system with an 8K context window often outperforms a naive implementation with 200K context. The million-token context windows are impressive technically, but for 90% of real-world use cases, they're solving the wrong problem. The real challenge isn't fitting more tokens into context. It's <a href="/posts/2025-10-17-progressive-context-loading-llm-workflows">intelligently selecting which tokens deserve to be there</a>.</p>
<hr>
<p><em>For those interested in exploring context window innovations further, <a href="https://www.anthropic.com/research">Anthropic's research on long-context language models</a> provides insights into optimization techniques, while the <a href="https://arxiv.org/abs/2009.06732">Efficient Transformers survey paper</a> offers comprehensive coverage of architectural improvements addressing these challenges.</em></p>

            </div>
            
            <!-- Related Posts -->
            
            
            
            
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                            
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                            
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                            
                        
                    
                        
                    
                    
                        
                    
                
            
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                            
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                            
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                            
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                            
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                            
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                    
                    
                        
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
                
                    
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                    
                
            
            
            
            
            <section aria-label="Content section" class="mt-16 pt-8 border-t border-gray-200 dark:border-gray-800">
                <h2 class="text-2xl font-bold mb-6 text-gray-900 dark:text-gray-100">Related Posts</h2>
                <div class="grid gap-6 md:grid-cols-2 lg:grid-cols-3">
                    
                    
                    <article class="group">
                        <a href="/posts/from-150k-to-2k-tokens-how-progressive-context-loading-revolutionizes-llm-development-workflows/" class="block p-6 bg-gray-50 dark:bg-gray-800 rounded-lg hover:bg-gray-100 dark:hover:bg-gray-700 transition-all duration-200 hover:shadow-md">
                            <h3 class="text-lg font-semibold text-gray-900 dark:text-gray-100 group-hover:text-primary-600 dark:group-hover:text-primary-400 mb-2">
                                From 150K to 2K Tokens: How Progressive Context Loading Revolutionizes LLM Development Workflows
                            </h3>
                            <p class="text-sm text-gray-600 dark:text-gray-400 mb-3">
                                Optimize LLM workflows with progressive context loading—achieve 98% token reduction using modular ar...
                            </p>
                            <div class="flex items-center justify-between text-xs text-gray-500 dark:text-gray-500">
                                <time datetime="2025-10-17">
                                    October 17, 2025
                                </time>
                                <span>15 min read</span>
                            </div>
                        </a>
                    </article>
                    
                    
                    <article class="group">
                        <a href="/posts/from-claude-in-your-terminal-to-robots-in-your-workshop-the-embodied-ai-revolution/" class="block p-6 bg-gray-50 dark:bg-gray-800 rounded-lg hover:bg-gray-100 dark:hover:bg-gray-700 transition-all duration-200 hover:shadow-md">
                            <h3 class="text-lg font-semibold text-gray-900 dark:text-gray-100 group-hover:text-primary-600 dark:group-hover:text-primary-400 mb-2">
                                From Claude in Your Terminal to Robots in Your Workshop: The Embodied AI Revolution
                            </h3>
                            <p class="text-sm text-gray-600 dark:text-gray-400 mb-3">
                                Deploy Vision-Language-Action models for embodied AI robots—integrate physical world interaction wit...
                            </p>
                            <div class="flex items-center justify-between text-xs text-gray-500 dark:text-gray-500">
                                <time datetime="2025-10-13">
                                    October 13, 2025
                                </time>
                                <span>8 min read</span>
                            </div>
                        </a>
                    </article>
                    
                    
                    <article class="group">
                        <a href="/posts/ai-as-cognitive-infrastructure-the-invisible-architecture-reshaping-human-thought/" class="block p-6 bg-gray-50 dark:bg-gray-800 rounded-lg hover:bg-gray-100 dark:hover:bg-gray-700 transition-all duration-200 hover:shadow-md">
                            <h3 class="text-lg font-semibold text-gray-900 dark:text-gray-100 group-hover:text-primary-600 dark:group-hover:text-primary-400 mb-2">
                                AI as Cognitive Infrastructure: The Invisible Architecture Reshaping Human Thought
                            </h3>
                            <p class="text-sm text-gray-600 dark:text-gray-400 mb-3">
                                Understand AI cognitive infrastructure shaping how billions think—explore societal effects of langua...
                            </p>
                            <div class="flex items-center justify-between text-xs text-gray-500 dark:text-gray-500">
                                <time datetime="2025-08-09">
                                    August 9, 2025
                                </time>
                                <span>10 min read</span>
                            </div>
                        </a>
                    </article>
                    
                </div>
            </section>
            
            
            <footer role="contentinfo" aria-label="Site footer" class="mt-16 pt-8 border-t border-gray-200 dark:border-gray-800">
                <div class="flex items-center justify-between">
                    <a href="/posts/" class="inline-flex items-center text-sm font-medium text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200 transition-colors duration-200">
                        <svg class="w-5 h-5 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7" />
                        </svg>
                        Back to all posts
                    </a>
                    
                    <div class="flex items-center space-x-4">
                        <span class="text-sm text-gray-500 dark:text-gray-400">Share:</span>
                        
                        <!-- LinkedIn -->
                        <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://williamzujkowski.github.io%2Fposts%2Fcontext-windows-in-large-language-models-the-memory-that-shapes-ai%2F" 
                           target="_blank" 
                           rel="noopener noreferrer" 
                           class="text-gray-400 hover:text-[#0077b5] dark:hover:text-[#0077b5] transition-colors duration-200"
                           aria-label="Share on LinkedIn">
                            <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
                            </svg>
                        </a>
                        
                        <!-- Hacker News -->
                        <a href="https://news.ycombinator.com/submitlink?u=https://williamzujkowski.github.io%2Fposts%2Fcontext-windows-in-large-language-models-the-memory-that-shapes-ai%2F&t=Context%20Windows%20in%20Large%20Language%20Models%3A%20The%20Memory%20That%20Shapes%20AI" 
                           target="_blank" 
                           rel="noopener noreferrer" 
                           class="text-gray-400 hover:text-[#ff6600] dark:hover:text-[#ff6600] transition-colors duration-200"
                           aria-label="Share on Hacker News">
                            <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M0 0v24h24v-24h-24zm12.8 8.7l2.3-4.3h1.4l-3.1 5.5v3.5h-1.2v-3.5l-3-5.5h1.4l2.2 4.3z"/>
                            </svg>
                        </a>
                        
                        <!-- Reddit -->
                        <a href="https://reddit.com/submit?url=https://williamzujkowski.github.io%2Fposts%2Fcontext-windows-in-large-language-models-the-memory-that-shapes-ai%2F&title=Context%20Windows%20in%20Large%20Language%20Models%3A%20The%20Memory%20That%20Shapes%20AI" 
                           target="_blank" 
                           rel="noopener noreferrer" 
                           class="text-gray-400 hover:text-[#ff4500] dark:hover:text-[#ff4500] transition-colors duration-200"
                           aria-label="Share on Reddit">
                            <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M24 11.779c0-1.459-1.192-2.645-2.657-2.645-.715 0-1.363.286-1.84.746-1.81-1.191-4.259-1.949-6.971-2.046l1.483-4.669 4.016.941-.006.058c0 1.193.975 2.163 2.174 2.163 1.198 0 2.172-.97 2.172-2.163s-.975-2.164-2.172-2.164c-.92 0-1.704.574-2.021 1.379l-4.329-1.015c-.189-.046-.381.063-.44.249l-1.654 5.207c-2.838.034-5.409.798-7.3 2.025-.474-.438-1.103-.712-1.799-.712-1.465 0-2.656 1.187-2.656 2.646 0 .97.533 1.811 1.317 2.271-.052.282-.086.567-.086.857 0 3.911 4.808 7.093 10.719 7.093s10.72-3.182 10.72-7.093c0-.274-.029-.544-.075-.81.832-.447 1.405-1.312 1.405-2.318zm-17.224 1.816c0-.868.71-1.575 1.582-1.575.872 0 1.581.707 1.581 1.575s-.709 1.574-1.581 1.574-1.582-.706-1.582-1.574zm9.061 4.669c-.797.793-2.048 1.179-3.824 1.179l-.013-.003-.013.003c-1.777 0-3.028-.386-3.824-1.179-.145-.144-.145-.379 0-.523.145-.145.381-.145.526 0 .65.647 1.729.961 3.298.961l.013.003.013-.003c1.569 0 2.648-.315 3.298-.962.145-.145.381-.144.526 0 .145.145.145.379 0 .524zm-.189-3.095c-.872 0-1.581-.706-1.581-1.574 0-.868.709-1.575 1.581-1.575s1.581.707 1.581 1.575-.709 1.574-1.581 1.574z"/>
                            </svg>
                        </a>
                        
                        <!-- Copy Link -->
                        <button onclick="copyToClipboard('https://williamzujkowski.github.io/posts/context-windows-in-large-language-models-the-memory-that-shapes-ai/')" 
                                class="text-gray-400 hover:text-gray-600 dark:hover:text-gray-200 transition-colors duration-200"
                                aria-label="Copy link to clipboard">
                            <svg class="w-5 h-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" />
                            </svg>
                        </button>
                    </div>
                </div>
            </footer>
        </div>
    </div>
</article>

<!-- Blog JavaScript Bundle (reading-progress, table-of-contents) -->
<script src="/assets/js/blog.min.js"></script>

<!-- Collapsible Code Blocks - loaded in base.njk -->
    </main>
    
    <!-- Footer -->
    <footer role="contentinfo" aria-label="Site footer" class="mt-auto border-t border-gray-200 dark:border-gray-800 bg-gray-50 dark:bg-gray-800/50">
        <div class="container mx-auto px-4 sm:px-6 lg:px-8 py-12">
            <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
                <!-- About -->
                <div>
                    <h3 class="text-sm font-semibold text-gray-900 dark:text-gray-100 uppercase tracking-wider mb-4">About</h3>
                    <p class="text-gray-600 dark:text-gray-400">
                        Personal website of William Zujkowski, exploring technology and sharing knowledge. All opinions and views expressed are my own and do not reflect those of my employer.
                    </p>
                </div>
                
                <!-- Quick Links -->
                <div>
                    <h3 class="text-sm font-semibold text-gray-900 dark:text-gray-100 uppercase tracking-wider mb-4">Quick Links</h3>
                    <ul class="space-y-2"><li><a href="/" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200">Home</a></li>
<li><a href="/about/" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200">About</a></li>
<li><a href="/posts/" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200">Posts</a></li>
<li><a href="/resources/" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200">Resources</a></li>
<li><a href="/stats/" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200">Stats</a></li>
<li><a href="/uses/" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200">Uses</a></li></ul>
                </div>
                
                <!-- Connect -->
                <div>
                    <h3 class="text-sm font-semibold text-gray-900 dark:text-gray-100 uppercase tracking-wider mb-4">Connect</h3>
                    <div class="flex space-x-4">
                        <a href="https://github.com/williamzujkowski" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200" aria-label="GitHub" rel="noopener noreferrer">
                            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                            </svg>
                        </a>
                        <a href="https://www.linkedin.com/in/williamzujkowski" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200" aria-label="LinkedIn" rel="noopener noreferrer">
                            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
                            </svg>
                        </a>
                        <a href="/feed.xml" class="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors duration-200" aria-label="RSS Feed">
                            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M3.429 5.1v2.4c7.248 0 13.114 5.886 13.114 13.142h2.4C18.943 12.18 11.858 5.1 3.429 5.1zm0 4.8v2.4c3.924 0 7.114 3.206 7.114 7.142h2.4c0-5.256-4.276-9.542-9.514-9.542zM6.171 16.386c-.756 0-1.371.615-1.371 1.371 0 .756.615 1.371 1.371 1.371.756 0 1.371-.615 1.371-1.371 0-.756-.615-1.371-1.371-1.371z"/>
                            </svg>
                        </a>
                    </div>
                </div>
            </div>
            
            <div class="mt-8 pt-8 border-t border-gray-200 dark:border-gray-700">
                <p class="text-center text-sm text-gray-600 dark:text-gray-400">
                    &copy; 2025 William Zujkowski. All rights reserved.
                    Built with <a href="https://www.11ty.dev/" class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300">Eleventy</a>
                    and <a href="https://tailwindcss.com/" class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300">Tailwind CSS</a>.
                </p>
            </div>
        </div>
    </footer>
    
    <!-- Scripts -->
    <script>
        function toggleDarkMode() {
            const html = document.documentElement;
            const themeColorMeta = document.querySelector('meta[name="theme-color"]');
            
            if (html.classList.contains('dark')) {
                html.classList.remove('dark');
                localStorage.theme = 'light';
                if (themeColorMeta) themeColorMeta.content = '#1e40af';
            } else {
                html.classList.add('dark');
                localStorage.theme = 'dark';
                if (themeColorMeta) themeColorMeta.content = '#111827';
            }
        }
        
        function copyToClipboard(text) {
            navigator.clipboard.writeText(text).then(function() {
                // Show success message
                showToast('Link copied to clipboard!');
            }, function(err) {
                // Fallback for older browsers
                const textArea = document.createElement("textarea");
                textArea.value = text;
                textArea.style.position = "fixed";
                textArea.style.left = "-999999px";
                textArea.style.top = "-999999px";
                document.body.appendChild(textArea);
                textArea.focus();
                textArea.select();
                try {
                    document.execCommand('copy');
                    showToast('Link copied to clipboard!');
                } catch (err) {
                    showToast('Failed to copy link');
                }
                document.body.removeChild(textArea);
            });
        }
        
        function showToast(message) {
            // Create toast element
            const toast = document.createElement('div');
            toast.className = 'fixed bottom-4 right-4 bg-gray-800 dark:bg-gray-200 text-white dark:text-gray-800 px-4 py-2 rounded-lg shadow-lg transform transition-all duration-300 translate-y-full';
            toast.textContent = message;
            document.body.appendChild(toast);
            
            // Animate in
            setTimeout(() => {
                toast.classList.remove('translate-y-full');
                toast.classList.add('translate-y-0');
            }, 10);
            
            // Remove after 3 seconds
            setTimeout(() => {
                toast.classList.remove('translate-y-0');
                toast.classList.add('translate-y-full');
                setTimeout(() => {
                    document.body.removeChild(toast);
                }, 300);
            }, 3000);
        }
        
        function toggleMobileMenu() {
            const menu = document.getElementById('mobile-menu');
            menu.classList.toggle('hidden');
        }
    </script>
    
    <!-- Core JavaScript Bundle (ui-enhancements, back-to-top, code-collapse) -->
    <script src="/assets/js/core.min.js"></script>
    
    <!-- Mermaid Diagram Support -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        
        // Determine if dark mode is active
        const isDarkMode = document.documentElement.classList.contains('dark');
        
        // Initialize mermaid with proper settings
        mermaid.initialize({ 
            startOnLoad: false, // We'll manually init after DOM manipulation
            theme: isDarkMode ? 'dark' : 'default',
            themeVariables: isDarkMode ? {
                // Dark mode theme
                primaryColor: '#4f46e5',
                primaryTextColor: '#f3f4f6',
                primaryBorderColor: '#6366f1',
                lineColor: '#4b5563',
                secondaryColor: '#374151',
                tertiaryColor: '#1f2937',
                background: '#111827',
                mainBkg: '#1f2937',
                secondBkg: '#374151',
                tertiaryBkg: '#4b5563',
                primaryBorderColor: '#6366f1',
                fontFamily: 'Inter, system-ui, sans-serif',
                fontSize: '16px',
                darkMode: true,
                nodeBkg: '#374151',
                nodeBorder: '#6366f1',
                clusterBkg: '#1f2937',
                clusterBorder: '#4b5563',
                defaultLinkColor: '#93bbfd',
                titleColor: '#f3f4f6',
                edgeLabelBackground: '#1f2937',
                actorBorder: '#6366f1',
                actorBkg: '#374151',
                actorTextColor: '#f3f4f6',
                actorLineColor: '#4b5563',
                signalColor: '#f3f4f6',
                signalTextColor: '#f3f4f6',
                labelBoxBkgColor: '#374151',
                labelBoxBorderColor: '#6366f1',
                labelTextColor: '#f3f4f6',
                loopTextColor: '#f3f4f6',
                noteBorderColor: '#6366f1',
                noteBkgColor: '#374151',
                noteTextColor: '#f3f4f6',
                activationBorderColor: '#6366f1',
                activationBkgColor: '#374151',
                sequenceNumberColor: '#111827'
            } : {
                // Light mode theme
                primaryColor: '#6366f1',
                primaryTextColor: '#fff',
                primaryBorderColor: '#4f46e5',
                lineColor: '#d1d5db',
                secondaryColor: '#e5e7eb',
                tertiaryColor: '#f3f4f6',
                background: '#ffffff',
                mainBkg: '#ffffff',
                secondBkg: '#f3f4f6',
                tertiaryBkg: '#e5e7eb',
                fontFamily: 'Inter, system-ui, sans-serif',
                fontSize: '16px',
                darkMode: false,
                nodeBkg: '#f3f4f6',
                nodeBorder: '#4f46e5',
                clusterBkg: '#e5e7eb',
                clusterBorder: '#9ca3af',
                defaultLinkColor: '#2563eb',
                titleColor: '#1f2937',
                edgeLabelBackground: '#ffffff',
                actorBorder: '#4f46e5',
                actorBkg: '#f3f4f6',
                actorTextColor: '#1f2937',
                actorLineColor: '#9ca3af',
                signalColor: '#1f2937',
                signalTextColor: '#1f2937',
                labelBoxBkgColor: '#f3f4f6',
                labelBoxBorderColor: '#4f46e5',
                labelTextColor: '#1f2937',
                loopTextColor: '#1f2937',
                noteBorderColor: '#4f46e5',
                noteBkgColor: '#f3f4f6',
                noteTextColor: '#1f2937',
                activationBorderColor: '#4f46e5',
                activationBkgColor: '#e5e7eb',
                sequenceNumberColor: '#ffffff'
            },
            securityLevel: 'loose',
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true
            }
        });
        
        // Process Mermaid diagrams and THEN initialize code-collapse
        window.addEventListener('DOMContentLoaded', async function() {
            // Step 1: Find and process all mermaid code blocks
            const mermaidBlocks = document.querySelectorAll('pre code.language-mermaid');
            
            if (mermaidBlocks.length > 0) {
                // Processing Mermaid diagrams
                
                // Convert each mermaid code block to a diagram
                for (const element of mermaidBlocks) {
                    const graphDefinition = element.textContent;
                    const preElement = element.parentNode;
                    
                    // Create a container div for the mermaid diagram
                    const containerDiv = document.createElement('div');
                    containerDiv.className = 'mermaid-container';
                    containerDiv.setAttribute('data-mermaid', 'true');
                    
                    // Create the mermaid div
                    const graphDiv = document.createElement('div');
                    graphDiv.className = 'mermaid';
                    graphDiv.textContent = graphDefinition;
                    
                    // Replace the pre element with the container - this removes the code block entirely
                    preElement.parentNode.replaceChild(containerDiv, preElement);
                    containerDiv.appendChild(graphDiv);
                }
                
                // Step 2: Initialize all mermaid diagrams with error handling
                try {
                    await mermaid.run();
                    console.log(`✅ Successfully rendered ${mermaidBlocks.length} Mermaid diagram(s)`);
                } catch (error) {
                    console.error('❌ Mermaid rendering failed:', error);
                    // Log each diagram's content for debugging
                    document.querySelectorAll('.mermaid').forEach((div, index) => {
                        console.error(`Diagram ${index + 1} content:`, div.textContent);
                    });
                }

                // Diagrams are now styled via CSS, no need for inline styles
            }
            
            // Step 3: Code-collapse.js is already loaded and will handle remaining blocks
            // It checks for data-processed attribute to avoid duplicates
        });
    </script>
</body>
</html>